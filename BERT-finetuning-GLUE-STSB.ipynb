{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-Tuning BERT on GLUE - STSB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From [Archive.org snapshot of dataset homepage](https://web.archive.org/web/20240319092902/http://ixa2.si.ehu.eus/stswiki/index.php/STSbenchmark):\n",
    "\n",
    "STS Benchmark comprises a selection of the English datasets used in the STS tasks organized in the context of SemEval between 2012 and 2017. The selection of datasets include text from image captions, news headlines and user forums. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Where to store the huggingface data. On the provided Jupyterlab instance that should be within the shared group folder.\n",
    "os.environ['HF_HOME'] = '../groups/192.039-2024W/bert/huggingface/cache'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from transformers import set_seed\n",
    "\n",
    "# RANDOMNESS SEED\n",
    "SEED = 42\n",
    "set_seed(SEED)\n",
    "\n",
    "# Which dataset to load\n",
    "DATASET_NAME = \"glue\"\n",
    "DATASET_TASK = \"stsb\"\n",
    "\n",
    "PRE_TRAINED_CHECKPOINT = \"google-bert/bert-base-uncased\"\n",
    "\n",
    "TRAIN_OUTPUT_DIR = (\n",
    "    Path(\"../groups/192.039-2024W/bert\") / \"training\" / f\"{DATASET_NAME}-{DATASET_TASK}\"\n",
    ")\n",
    "\n",
    "BATCH_SIZE = 32  # Original Paper claims to use 32 for GLUE tasks\n",
    "NUM_EPOCHS = 5  # Original Paper claims to use 3 fine-tuning epochs for GLUE tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "GPU used: NVIDIA GeForce RTX 4060 Ti\n",
      "\n",
      "==============NVSMI LOG==============\n",
      "\n",
      "Timestamp                                 : Sat Jan  4 17:57:51 2025\n",
      "Driver Version                            : 550.135\n",
      "CUDA Version                              : 12.4\n",
      "\n",
      "Attached GPUs                             : 1\n",
      "GPU 00000000:07:00.0\n",
      "    FB Memory Usage\n",
      "        Total                             : 16380 MiB\n",
      "        Reserved                          : 307 MiB\n",
      "        Used                              : 9135 MiB\n",
      "        Free                              : 6939 MiB\n",
      "    BAR1 Memory Usage\n",
      "        Total                             : 256 MiB\n",
      "        Used                              : 28 MiB\n",
      "        Free                              : 228 MiB\n",
      "    Conf Compute Protected Memory Usage\n",
      "        Total                             : 0 MiB\n",
      "        Used                              : 0 MiB\n",
      "        Free                              : 0 MiB\n",
      "    Compute Mode                          : Default\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "  device = torch.device(\"cuda\")\n",
    "  device_count = torch.cuda.device_count()\n",
    "  device_name = torch.cuda.get_device_name(0)\n",
    "\n",
    "  print(f\"There are {device_count} GPU(s) available.\")\n",
    "  print(f\"GPU used: {device_name}\")\n",
    "  ! nvidia-smi -q --display=MEMORY,COMPUTE\n",
    "\n",
    "else:\n",
    "  print(\"No GPU available, using CPU.\")\n",
    "  device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the GLUE dataset different tasks have different accessor keys\n",
    "_task_to_keys = {\n",
    "    \"cola\": (\"sentence\", None),\n",
    "    \"mnli\": (\"premise\", \"hypothesis\"),\n",
    "    \"mnli-mm\": (\"premise\", \"hypothesis\"),\n",
    "    \"mrpc\": (\"sentence1\", \"sentence2\"),\n",
    "    \"qnli\": (\"question\", \"sentence\"),\n",
    "    \"qqp\": (\"question1\", \"question2\"),\n",
    "    \"rte\": (\"sentence1\", \"sentence2\"),\n",
    "    \"sst2\": (\"sentence\", None),\n",
    "    \"stsb\": (\"sentence1\", \"sentence2\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
       "        num_rows: 5749\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
       "        num_rows: 1500\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
       "        num_rows: 1379\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "dataset = load_dataset(DATASET_NAME, DATASET_TASK)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>label</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4034</th>\n",
       "      <td>More than 30 striking miners killed</td>\n",
       "      <td>More than 30 striking miners killed in South A...</td>\n",
       "      <td>3.800</td>\n",
       "      <td>4034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5241</th>\n",
       "      <td>Sony Xperia Z2 and Nokia‚Äôs X series unveiled</td>\n",
       "      <td>Court orders political ban on Italy‚Äôs Berlus...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2201</th>\n",
       "      <td>He's not wealthy because he's successful.</td>\n",
       "      <td>Why hate people because they are successful?</td>\n",
       "      <td>0.800</td>\n",
       "      <td>2201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4211</th>\n",
       "      <td>Three more US soldiers killed in Afghanistan</td>\n",
       "      <td>NATO Soldier Killed in Afghanistan</td>\n",
       "      <td>1.800</td>\n",
       "      <td>4211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2671</th>\n",
       "      <td>The songs are on offer for 99 cents each, or $...</td>\n",
       "      <td>The company will offer songs for 99 cents and ...</td>\n",
       "      <td>3.333</td>\n",
       "      <td>2671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3268</th>\n",
       "      <td>In a not-too-subtle swipe at Dean, he predicte...</td>\n",
       "      <td>They will not elect as president a Democrat wh...</td>\n",
       "      <td>3.500</td>\n",
       "      <td>3268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1161</th>\n",
       "      <td>A small white dog chews on a twig while lying ...</td>\n",
       "      <td>The white dog is laying on the wooden floor un...</td>\n",
       "      <td>1.600</td>\n",
       "      <td>1161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3250</th>\n",
       "      <td>Still, he noted Miami must decide whether to s...</td>\n",
       "      <td>Still, he noted that Miami must decide whether...</td>\n",
       "      <td>4.600</td>\n",
       "      <td>3250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5333</th>\n",
       "      <td>Puerto Rican arrested for production of child ...</td>\n",
       "      <td>Indian guru arrested on suspicion of rape</td>\n",
       "      <td>0.400</td>\n",
       "      <td>5333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1874</th>\n",
       "      <td>A woman dressed in green is playing with her t...</td>\n",
       "      <td>A tan dog licks a girls hand while laying down.</td>\n",
       "      <td>1.600</td>\n",
       "      <td>1874</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              sentence1  \\\n",
       "4034                More than 30 striking miners killed   \n",
       "5241     Sony Xperia Z2 and Nokia‚Äôs X series unveiled   \n",
       "2201          He's not wealthy because he's successful.   \n",
       "4211       Three more US soldiers killed in Afghanistan   \n",
       "2671  The songs are on offer for 99 cents each, or $...   \n",
       "3268  In a not-too-subtle swipe at Dean, he predicte...   \n",
       "1161  A small white dog chews on a twig while lying ...   \n",
       "3250  Still, he noted Miami must decide whether to s...   \n",
       "5333  Puerto Rican arrested for production of child ...   \n",
       "1874  A woman dressed in green is playing with her t...   \n",
       "\n",
       "                                              sentence2  label   idx  \n",
       "4034  More than 30 striking miners killed in South A...  3.800  4034  \n",
       "5241  Court orders political ban on Italy‚Äôs Berlus...  0.000  5241  \n",
       "2201       Why hate people because they are successful?  0.800  2201  \n",
       "4211                 NATO Soldier Killed in Afghanistan  1.800  4211  \n",
       "2671  The company will offer songs for 99 cents and ...  3.333  2671  \n",
       "3268  They will not elect as president a Democrat wh...  3.500  3268  \n",
       "1161  The white dog is laying on the wooden floor un...  1.600  1161  \n",
       "3250  Still, he noted that Miami must decide whether...  4.600  3250  \n",
       "5333          Indian guru arrested on suspicion of rape  0.400  5333  \n",
       "1874    A tan dog licks a girls hand while laying down.  1.600  1874  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(dataset[\"train\"]).sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the STSB task each sentence pair is human-annotated with a similarity score from 1 to 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique_lables_in_dataset=array([5.        , 3.79999995, 2.5999999 , 4.25      , 0.5       ,\n",
      "       1.60000002, 2.20000005, 4.19999981, 4.5999999 , 3.8670001 ,\n",
      "       4.66699982, 1.66700006, 3.75      , 3.20000005, 2.79999995,\n",
      "       3.        , 4.80000019, 4.        , 4.90899992, 2.4000001 ,\n",
      "       3.4000001 , 2.75      , 3.5999999 , 1.75      , 1.        ,\n",
      "       2.375     , 4.4000001 , 4.75      , 1.55599999, 3.93799996,\n",
      "       3.5       , 1.39999998, 3.83299994, 0.60000002, 2.91700006,\n",
      "       2.        , 0.80000001, 1.64300001, 2.25      , 4.85699987,\n",
      "       2.53299999, 0.14300001, 2.5       , 0.        , 0.40000001,\n",
      "       0.667     , 4.1329999 , 1.20000005, 3.7650001 , 3.94099998,\n",
      "       0.25      , 3.25      , 0.75      , 1.5       , 0.2       ,\n",
      "       3.11100006, 1.28600001, 1.79999995, 0.85000002, 3.9230001 ,\n",
      "       1.25      , 0.833     , 0.333     , 3.33299994, 4.33300018,\n",
      "       2.66700006, 0.417     , 2.81800008, 3.53299999, 0.64300001,\n",
      "       1.58299994, 1.778     , 3.66700006, 2.33299994, 1.70000005,\n",
      "       4.5       , 0.727     , 1.33299994, 0.067     , 4.875     ,\n",
      "       3.61500001, 2.875     , 4.09100008, 2.76900005, 2.58299994,\n",
      "       3.9289999 , 0.23100001, 0.118     , 4.0999999 , 2.32999992,\n",
      "       0.17      , 3.67000008, 2.82999992, 3.0999999 , 2.11111116,\n",
      "       1.10000002, 3.77777767, 4.57142878, 2.4666667 , 0.89999998,\n",
      "       1.5333333 , 3.84599996, 3.875     , 1.84599996, 2.64700007,\n",
      "       3.06699991, 4.77799988, 4.36399984, 3.78600001, 4.92299986,\n",
      "       4.5710001 , 3.16700006, 0.94400001, 3.05599999, 4.81799984,\n",
      "       3.23099995, 4.72700024, 1.73300004, 2.90899992, 3.43799996,\n",
      "       4.17600012, 2.625     , 3.45499992, 4.05600023, 3.64299989,\n",
      "       3.69199991, 3.85700011, 1.273     , 2.58800006, 3.44400001,\n",
      "       0.889     , 3.273     , 2.70000005, 3.90899992, 3.93300009,\n",
      "       3.76900005, 3.625     , 4.30800009, 3.33333325, 4.32999992])\n",
      "num_labels=1\n"
     ]
    }
   ],
   "source": [
    "unique_lables_in_dataset = pd.DataFrame(dataset[\"train\"])[\"label\"].unique()\n",
    "num_labels = 1\n",
    "\n",
    "print(f\"{unique_lables_in_dataset=}\")\n",
    "print(f\"{num_labels=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(PRE_TRAINED_CHECKPOINT, do_lower_case=\"uncased\" in PRE_TRAINED_CHECKPOINT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BERT has a maximum sequence length of 512. We can check the sequence lengths resulting from tokenizing our dataset to see if our dataset exceeds this restriction of BERT:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length in split='train': 125\n",
      "Max length in split='validation': 87\n",
      "Max length in split='test': 81\n"
     ]
    }
   ],
   "source": [
    "first_sentence_key, second_sentence_key = _task_to_keys[DATASET_TASK]\n",
    "\n",
    "if second_sentence_key == None:  # Simply tokenize sentence\n",
    "\n",
    "    for split in dataset.keys():\n",
    "        max_len = 0\n",
    "        for sentence in dataset[split][first_sentence_key]:\n",
    "            # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
    "            input_ids = tokenizer.encode(sentence, add_special_tokens=True)\n",
    "            \n",
    "            max_len = max(max_len, len(input_ids))\n",
    "        \n",
    "\n",
    "        print(f\"Max length in {split=}: {max_len}\")\n",
    "\n",
    "else:  # Append both sentences via [SEP] and tokenize\n",
    "\n",
    "    for split in dataset.keys():\n",
    "        max_len = 0\n",
    "        for sentence1, sentence2 in zip(dataset[split][first_sentence_key], dataset[split][second_sentence_key]):\n",
    "            # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
    "            input_ids = tokenizer.encode(sentence1, sentence2,  add_special_tokens=True)\n",
    "            \n",
    "            max_len = max(max_len, len(input_ids))\n",
    "        \n",
    "\n",
    "        print(f\"Max length in {split=}: {max_len}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39df8e48b3614582be20a9cbda932e15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5749 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d66c05d95bb4d50978105fdb307cfab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a5e52305d914af38958e98b796c6f2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1379 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize_func(item):\n",
    "    \"\"\"Tokenize passed item. \n",
    "    \n",
    "    Depending on dataset task the passed item will either contain one sentence or two sentences.\n",
    "    In the last case the two sentences will be appended via a [SEP] token.\n",
    "    \"\"\"\n",
    "    if second_sentence_key is None:\n",
    "        return tokenizer(item[first_sentence_key], add_special_tokens=True, truncation=True)\n",
    "    else:\n",
    "        return tokenizer(item[first_sentence_key], item[second_sentence_key], add_special_tokens=True, truncation=True)\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_func, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example of a tokenized dataset item:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence1': ['A plane is taking off.'],\n",
       " 'sentence2': ['An air plane is taking off.'],\n",
       " 'label': [5.0],\n",
       " 'idx': [0]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence1': ['A plane is taking off.'],\n",
       " 'sentence2': ['An air plane is taking off.'],\n",
       " 'label': [5.0],\n",
       " 'idx': [0],\n",
       " 'input_ids': [[101,\n",
       "   1037,\n",
       "   4946,\n",
       "   2003,\n",
       "   2635,\n",
       "   2125,\n",
       "   1012,\n",
       "   102,\n",
       "   2019,\n",
       "   2250,\n",
       "   4946,\n",
       "   2003,\n",
       "   2635,\n",
       "   2125,\n",
       "   1012,\n",
       "   102]],\n",
       " 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       " 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset[\"train\"][:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenization added the `input_ids` field, which contains the tokenized sentence with a `[CLS]`(101) and two `[SEP]`(102) tokens added. A `token_type_ids` field which indicates first and second portion of the inputs, if necessary. And an `attention_mask` for the given input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with Padding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Huggingface's `transformers` library provides a `DataCollatorWithPadding` class, which allows us to use dynamic padding.  \n",
    "Dynamic padding will add `[PAD]` tokens to the length of the longest sequence within a batch, instead of padding to the maximum sequence length within the entire dataset.  \n",
    "This will avoid unnecessary padding and therefore improve execution efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>1037</td>\n",
       "      <td>4946</td>\n",
       "      <td>2003</td>\n",
       "      <td>2635</td>\n",
       "      <td>2125</td>\n",
       "      <td>1012</td>\n",
       "      <td>102</td>\n",
       "      <td>2019</td>\n",
       "      <td>2250</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101</td>\n",
       "      <td>1037</td>\n",
       "      <td>2158</td>\n",
       "      <td>2003</td>\n",
       "      <td>2652</td>\n",
       "      <td>1037</td>\n",
       "      <td>2312</td>\n",
       "      <td>8928</td>\n",
       "      <td>1012</td>\n",
       "      <td>102</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101</td>\n",
       "      <td>1037</td>\n",
       "      <td>2158</td>\n",
       "      <td>2003</td>\n",
       "      <td>9359</td>\n",
       "      <td>14021</td>\n",
       "      <td>5596</td>\n",
       "      <td>2098</td>\n",
       "      <td>8808</td>\n",
       "      <td>2006</td>\n",
       "      <td>...</td>\n",
       "      <td>29022.0</td>\n",
       "      <td>8808.0</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>4895.0</td>\n",
       "      <td>3597.0</td>\n",
       "      <td>23461.0</td>\n",
       "      <td>10733.0</td>\n",
       "      <td>1012.0</td>\n",
       "      <td>102.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0     1     2     3     4      5     6     7     8     9   ...       18  \\\n",
       "0  101  1037  4946  2003  2635   2125  1012   102  2019  2250  ...      NaN   \n",
       "1  101  1037  2158  2003  2652   1037  2312  8928  1012   102  ...      NaN   \n",
       "2  101  1037  2158  2003  9359  14021  5596  2098  8808  2006  ...  29022.0   \n",
       "\n",
       "       19      20      21      22      23       24       25      26     27  \n",
       "0     NaN     NaN     NaN     NaN     NaN      NaN      NaN     NaN    NaN  \n",
       "1     NaN     NaN     NaN     NaN     NaN      NaN      NaN     NaN    NaN  \n",
       "2  8808.0  2006.0  2019.0  4895.0  3597.0  23461.0  10733.0  1012.0  102.0  \n",
       "\n",
       "[3 rows x 28 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "# Example: Select a few samples from the training set\n",
    "samples = tokenized_dataset[\"train\"][:3]\n",
    "samples = {k: v for k, v in samples.items() if k not in [\"idx\", first_sentence_key, second_sentence_key]}  # Drop `idx` and `sentence` columns, as DataCollator can't process those.\n",
    "pd.DataFrame(samples[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>1037</td>\n",
       "      <td>4946</td>\n",
       "      <td>2003</td>\n",
       "      <td>2635</td>\n",
       "      <td>2125</td>\n",
       "      <td>1012</td>\n",
       "      <td>102</td>\n",
       "      <td>2019</td>\n",
       "      <td>2250</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101</td>\n",
       "      <td>1037</td>\n",
       "      <td>2158</td>\n",
       "      <td>2003</td>\n",
       "      <td>2652</td>\n",
       "      <td>1037</td>\n",
       "      <td>2312</td>\n",
       "      <td>8928</td>\n",
       "      <td>1012</td>\n",
       "      <td>102</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101</td>\n",
       "      <td>1037</td>\n",
       "      <td>2158</td>\n",
       "      <td>2003</td>\n",
       "      <td>9359</td>\n",
       "      <td>14021</td>\n",
       "      <td>5596</td>\n",
       "      <td>2098</td>\n",
       "      <td>8808</td>\n",
       "      <td>2006</td>\n",
       "      <td>...</td>\n",
       "      <td>29022</td>\n",
       "      <td>8808</td>\n",
       "      <td>2006</td>\n",
       "      <td>2019</td>\n",
       "      <td>4895</td>\n",
       "      <td>3597</td>\n",
       "      <td>23461</td>\n",
       "      <td>10733</td>\n",
       "      <td>1012</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0     1     2     3     4      5     6     7     8     9   ...     18  \\\n",
       "0  101  1037  4946  2003  2635   2125  1012   102  2019  2250  ...      0   \n",
       "1  101  1037  2158  2003  2652   1037  2312  8928  1012   102  ...      0   \n",
       "2  101  1037  2158  2003  9359  14021  5596  2098  8808  2006  ...  29022   \n",
       "\n",
       "     19    20    21    22    23     24     25    26   27  \n",
       "0     0     0     0     0     0      0      0     0    0  \n",
       "1     0     0     0     0     0      0      0     0    0  \n",
       "2  8808  2006  2019  4895  3597  23461  10733  1012  102  \n",
       "\n",
       "[3 rows x 28 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply padding using data_collator\n",
    "batch = data_collator(samples)\n",
    "pd.DataFrame(batch[\"input_ids\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that `data_collator` will insert `[PAD]` (0) tokens to the maximum length of the passed batch of data items."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The GLUE dataset specifies one or more evaluation metrics depending on the selected task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EvaluationModule(name: \"glue\", module_type: \"metric\", features: {'predictions': Value(dtype='float32', id=None), 'references': Value(dtype='float32', id=None)}, usage: \"\"\"\n",
       "Compute GLUE evaluation metric associated to each GLUE dataset.\n",
       "Args:\n",
       "    predictions: list of predictions to score.\n",
       "        Each translation should be tokenized into a list of tokens.\n",
       "    references: list of lists of references for each translation.\n",
       "        Each reference should be tokenized into a list of tokens.\n",
       "Returns: depending on the GLUE subset, one or several of:\n",
       "    \"accuracy\": Accuracy\n",
       "    \"f1\": F1 score\n",
       "    \"pearson\": Pearson Correlation\n",
       "    \"spearmanr\": Spearman Correlation\n",
       "    \"matthews_correlation\": Matthew Correlation\n",
       "Examples:\n",
       "\n",
       "    >>> glue_metric = evaluate.load('glue', 'sst2')  # 'sst2' or any of [\"mnli\", \"mnli_mismatched\", \"mnli_matched\", \"qnli\", \"rte\", \"wnli\", \"hans\"]\n",
       "    >>> references = [0, 1]\n",
       "    >>> predictions = [0, 1]\n",
       "    >>> results = glue_metric.compute(predictions=predictions, references=references)\n",
       "    >>> print(results)\n",
       "    {'accuracy': 1.0}\n",
       "\n",
       "    >>> glue_metric = evaluate.load('glue', 'mrpc')  # 'mrpc' or 'qqp'\n",
       "    >>> references = [0, 1]\n",
       "    >>> predictions = [0, 1]\n",
       "    >>> results = glue_metric.compute(predictions=predictions, references=references)\n",
       "    >>> print(results)\n",
       "    {'accuracy': 1.0, 'f1': 1.0}\n",
       "\n",
       "    >>> glue_metric = evaluate.load('glue', 'stsb')\n",
       "    >>> references = [0., 1., 2., 3., 4., 5.]\n",
       "    >>> predictions = [0., 1., 2., 3., 4., 5.]\n",
       "    >>> results = glue_metric.compute(predictions=predictions, references=references)\n",
       "    >>> print({\"pearson\": round(results[\"pearson\"], 2), \"spearmanr\": round(results[\"spearmanr\"], 2)})\n",
       "    {'pearson': 1.0, 'spearmanr': 1.0}\n",
       "\n",
       "    >>> glue_metric = evaluate.load('glue', 'cola')\n",
       "    >>> references = [0, 1]\n",
       "    >>> predictions = [0, 1]\n",
       "    >>> results = glue_metric.compute(predictions=predictions, references=references)\n",
       "    >>> print(results)\n",
       "    {'matthews_correlation': 1.0}\n",
       "\"\"\", stored examples: 0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(DATASET_NAME, DATASET_TASK)\n",
    "metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on the selected GLUE task we optimize for different evaluation metrics. See BERT paper p.6:\n",
    "\n",
    "> F1 scores are reported for QQP and MRPC, Spearman correlations are reported for STS-B, and accuracy scores are reported for the other tasks. We exclude entries that use BERT as one of their components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "_task_to_metric = {\n",
    "    \"cola\": \"matthews_correlation\",\n",
    "    \"mnli\": \"accuracy\",\n",
    "    \"mnli-mm\": \"accuracy\",\n",
    "    \"mrpc\": \"f1\",\n",
    "    \"qnli\": \"accuracy\",\n",
    "    \"qqp\": \"f1\",\n",
    "    \"rte\": \"accuracy\",\n",
    "    \"sst2\": \"accuracy\",\n",
    "    \"stsb\": \"spearmanr\",\n",
    "}\n",
    "\n",
    "metric_for_best_model = _task_to_metric[DATASET_TASK]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We will use \"['pearson', 'spearmanr']\" as an evaluation metric for the task stsb\n"
     ]
    }
   ],
   "source": [
    "def get_metric_name_for_specific_task():\n",
    "    \"\"\"Helper function to derive the evaluation metric name for the specified GLUE task.\n",
    "\n",
    "    The tasks specified by the GLUE benchmark use different evaluation metrics.\n",
    "    Unfortunatly there is no easy way to derive there name after loading the corresponding metric function via HuggingFace's `evaluate` library.\n",
    "    However we can simply do a \"trial run\" and expect the name key of its output.\n",
    "    \"\"\"\n",
    "    output = metric.compute(\n",
    "        predictions=[1, 0], references=[1, 1]\n",
    "    )  # dummy input - we just want to inspect the returned dictionary.\n",
    "    metric_names = output.keys()\n",
    "    \n",
    "    return list(metric_names)\n",
    "\n",
    "\n",
    "metric_names = get_metric_name_for_specific_task()\n",
    "print(f'We will use \"{metric_names}\" as an evaluation metric for the task {DATASET_TASK}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert metric_for_best_model in metric_names, \"Metric to optimize for not found in evaluation metrics provided by GLUE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For STSB `num_labels = 1`. This will result in `AutoModelForSequenceClassification` actually triggering the regression modeling, and the loss function will be set to `MSELoss()`.  \n",
    "See `transformers` library implementation [here](https://github.com/huggingface/transformers/blob/7ae6f070044b0171a71f3269613bf02fd9fca6f2/src/transformers/models/bert/modeling_bert.py#L1564-L1575)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    PRE_TRAINED_CHECKPOINT,\n",
    "    num_labels=num_labels,\n",
    "    torch_dtype=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_arguments = TrainingArguments(\n",
    "    output_dir=TRAIN_OUTPUT_DIR,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=100,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=100,\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=100,\n",
    "    num_train_epochs=NUM_EPOCHS,\n",
    "    learning_rate=2e-5,  # Original paper uses best out of  5e-5, 4e-5, 3e-5, and 2e-5\n",
    "    weight_decay=0.01,  # Original paper uses 0.01 on pre-training\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=metric_for_best_model,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    if DATASET_TASK != \"stsb\":\n",
    "        predictions = np.argmax(predictions, axis=1)\n",
    "    else:\n",
    "        predictions = predictions[:, 0]\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "validation_key = \"validation_mismatched\" if DATASET_TASK == \"mnli-mm\" else \"validation_matched\" if DATASET_TASK == \"mnli\" else \"validation\"\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_arguments,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[validation_key],\n",
    "    data_collator=data_collator,\n",
    "    processing_class=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- training_arguments.output_dir='../groups/192.039-2024W/bert/training/glue-stsb'\n",
      "--- training_arguments.metric_for_best_model='spearmanr'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "063bedb053aa44f8bc8f36017cccd3d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/900 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0545, 'grad_norm': 12.394493103027344, 'learning_rate': 1.7777777777777777e-05, 'epoch': 0.56}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93f9c70b40604244a9b727c7e3d47662",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6414876580238342, 'eval_pearson': 0.8523198366165161, 'eval_spearmanr': 0.84718479920071, 'eval_runtime': 1.6579, 'eval_samples_per_second': 904.782, 'eval_steps_per_second': 28.35, 'epoch': 0.56}\n",
      "{'loss': 0.6736, 'grad_norm': 14.725046157836914, 'learning_rate': 1.555555555555556e-05, 'epoch': 1.11}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1b2374c76a9497ab3c2669b8d2612a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6297786831855774, 'eval_pearson': 0.8723599314689636, 'eval_spearmanr': 0.8700897064463456, 'eval_runtime': 1.6031, 'eval_samples_per_second': 935.678, 'eval_steps_per_second': 29.318, 'epoch': 1.11}\n",
      "{'loss': 0.5231, 'grad_norm': 9.297086715698242, 'learning_rate': 1.3333333333333333e-05, 'epoch': 1.67}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f4e5403edfd492cb31b59378b4a94c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5273382067680359, 'eval_pearson': 0.8773388862609863, 'eval_spearmanr': 0.8754828863200265, 'eval_runtime': 1.5963, 'eval_samples_per_second': 939.658, 'eval_steps_per_second': 29.443, 'epoch': 1.67}\n",
      "{'loss': 0.4289, 'grad_norm': 11.710603713989258, 'learning_rate': 1.1111111111111113e-05, 'epoch': 2.22}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7d56aaeb52b495ab6d102f20cf73e0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5121705532073975, 'eval_pearson': 0.8814891576766968, 'eval_spearmanr': 0.8775124055124096, 'eval_runtime': 1.612, 'eval_samples_per_second': 930.524, 'eval_steps_per_second': 29.156, 'epoch': 2.22}\n",
      "{'loss': 0.3531, 'grad_norm': 8.986407279968262, 'learning_rate': 8.888888888888888e-06, 'epoch': 2.78}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "792f030a049042d49612091ffc7579d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5202115178108215, 'eval_pearson': 0.8821995258331299, 'eval_spearmanr': 0.8789760559873814, 'eval_runtime': 1.5864, 'eval_samples_per_second': 945.514, 'eval_steps_per_second': 29.626, 'epoch': 2.78}\n",
      "{'loss': 0.2902, 'grad_norm': 6.865576267242432, 'learning_rate': 6.666666666666667e-06, 'epoch': 3.33}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa379f8ce1fe40beb62dffb982d3033f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5698310732841492, 'eval_pearson': 0.8838173747062683, 'eval_spearmanr': 0.8807719042002081, 'eval_runtime': 1.6062, 'eval_samples_per_second': 933.861, 'eval_steps_per_second': 29.261, 'epoch': 3.33}\n",
      "{'loss': 0.251, 'grad_norm': 8.357426643371582, 'learning_rate': 4.444444444444444e-06, 'epoch': 3.89}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "871a62d2e84747c78b4bf16e43065443",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5156366229057312, 'eval_pearson': 0.8829105496406555, 'eval_spearmanr': 0.8800418076116006, 'eval_runtime': 1.598, 'eval_samples_per_second': 938.691, 'eval_steps_per_second': 29.412, 'epoch': 3.89}\n",
      "{'loss': 0.2185, 'grad_norm': 7.356443881988525, 'learning_rate': 2.222222222222222e-06, 'epoch': 4.44}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78740f3a7d1f4f2e9b3ac58bdce9a644",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5483375787734985, 'eval_pearson': 0.8824662566184998, 'eval_spearmanr': 0.8796938251653577, 'eval_runtime': 1.5995, 'eval_samples_per_second': 937.795, 'eval_steps_per_second': 29.384, 'epoch': 4.44}\n",
      "{'loss': 0.2107, 'grad_norm': 9.082740783691406, 'learning_rate': 0.0, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acba40366e534575b0cac132740f0d0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5260419249534607, 'eval_pearson': 0.8830761909484863, 'eval_spearmanr': 0.8798237523011697, 'eval_runtime': 1.5994, 'eval_samples_per_second': 937.83, 'eval_steps_per_second': 29.385, 'epoch': 5.0}\n",
      "{'train_runtime': 183.4151, 'train_samples_per_second': 156.721, 'train_steps_per_second': 4.907, 'train_loss': 0.5559741253323025, 'epoch': 5.0}\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "print(f\"--- {training_arguments.output_dir=}\")\n",
    "print(f\"--- {training_arguments.metric_for_best_model=}\")\n",
    "training_summary = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=900, training_loss=0.5559741253323025, metrics={'train_runtime': 183.4151, 'train_samples_per_second': 156.721, 'train_steps_per_second': 4.907, 'total_flos': 1026875201319492.0, 'train_loss': 0.5559741253323025, 'epoch': 5.0})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can call `trainer.evaluate()` to check that the `trainer` instance did indeed reload the model checkpoint with the highest evaluation score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "272594051de041329a832f7cd1cab145",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.5698310732841492,\n",
       " 'eval_pearson': 0.8838173747062683,\n",
       " 'eval_spearmanr': 0.8807719042002081,\n",
       " 'eval_runtime': 1.611,\n",
       " 'eval_samples_per_second': 931.084,\n",
       " 'eval_steps_per_second': 29.174,\n",
       " 'epoch': 5.0}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>grad_norm</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>epoch</th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>eval_pearson</th>\n",
       "      <th>eval_spearmanr</th>\n",
       "      <th>eval_runtime</th>\n",
       "      <th>eval_samples_per_second</th>\n",
       "      <th>eval_steps_per_second</th>\n",
       "      <th>train_runtime</th>\n",
       "      <th>train_samples_per_second</th>\n",
       "      <th>train_steps_per_second</th>\n",
       "      <th>total_flos</th>\n",
       "      <th>train_loss</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>step</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>2.0545</td>\n",
       "      <td>12.394493</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.641488</td>\n",
       "      <td>0.852320</td>\n",
       "      <td>0.847185</td>\n",
       "      <td>1.6579</td>\n",
       "      <td>904.782</td>\n",
       "      <td>28.350</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>0.6736</td>\n",
       "      <td>14.725046</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>1.111111</td>\n",
       "      <td>0.629779</td>\n",
       "      <td>0.872360</td>\n",
       "      <td>0.870090</td>\n",
       "      <td>1.6031</td>\n",
       "      <td>935.678</td>\n",
       "      <td>29.318</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>0.5231</td>\n",
       "      <td>9.297087</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.527338</td>\n",
       "      <td>0.877339</td>\n",
       "      <td>0.875483</td>\n",
       "      <td>1.5963</td>\n",
       "      <td>939.658</td>\n",
       "      <td>29.443</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>0.4289</td>\n",
       "      <td>11.710604</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>2.222222</td>\n",
       "      <td>0.512171</td>\n",
       "      <td>0.881489</td>\n",
       "      <td>0.877512</td>\n",
       "      <td>1.6120</td>\n",
       "      <td>930.524</td>\n",
       "      <td>29.156</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>0.3531</td>\n",
       "      <td>8.986407</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>2.777778</td>\n",
       "      <td>0.520212</td>\n",
       "      <td>0.882200</td>\n",
       "      <td>0.878976</td>\n",
       "      <td>1.5864</td>\n",
       "      <td>945.514</td>\n",
       "      <td>29.626</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>0.2902</td>\n",
       "      <td>6.865576</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>0.569831</td>\n",
       "      <td>0.883817</td>\n",
       "      <td>0.880772</td>\n",
       "      <td>1.6062</td>\n",
       "      <td>933.861</td>\n",
       "      <td>29.261</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>0.2510</td>\n",
       "      <td>8.357427</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>3.888889</td>\n",
       "      <td>0.515637</td>\n",
       "      <td>0.882911</td>\n",
       "      <td>0.880042</td>\n",
       "      <td>1.5980</td>\n",
       "      <td>938.691</td>\n",
       "      <td>29.412</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>0.2185</td>\n",
       "      <td>7.356444</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>4.444444</td>\n",
       "      <td>0.548338</td>\n",
       "      <td>0.882466</td>\n",
       "      <td>0.879694</td>\n",
       "      <td>1.5995</td>\n",
       "      <td>937.795</td>\n",
       "      <td>29.384</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>0.2107</td>\n",
       "      <td>9.082741</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.526042</td>\n",
       "      <td>0.883076</td>\n",
       "      <td>0.879824</td>\n",
       "      <td>1.5994</td>\n",
       "      <td>937.830</td>\n",
       "      <td>29.385</td>\n",
       "      <td>183.4151</td>\n",
       "      <td>156.721</td>\n",
       "      <td>4.907</td>\n",
       "      <td>1.026875e+15</td>\n",
       "      <td>0.555974</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        loss  grad_norm  learning_rate     epoch  eval_loss  eval_pearson  \\\n",
       "step                                                                        \n",
       "100   2.0545  12.394493       0.000018  0.555556   0.641488      0.852320   \n",
       "200   0.6736  14.725046       0.000016  1.111111   0.629779      0.872360   \n",
       "300   0.5231   9.297087       0.000013  1.666667   0.527338      0.877339   \n",
       "400   0.4289  11.710604       0.000011  2.222222   0.512171      0.881489   \n",
       "500   0.3531   8.986407       0.000009  2.777778   0.520212      0.882200   \n",
       "600   0.2902   6.865576       0.000007  3.333333   0.569831      0.883817   \n",
       "700   0.2510   8.357427       0.000004  3.888889   0.515637      0.882911   \n",
       "800   0.2185   7.356444       0.000002  4.444444   0.548338      0.882466   \n",
       "900   0.2107   9.082741       0.000000  5.000000   0.526042      0.883076   \n",
       "\n",
       "      eval_spearmanr  eval_runtime  eval_samples_per_second  \\\n",
       "step                                                          \n",
       "100         0.847185        1.6579                  904.782   \n",
       "200         0.870090        1.6031                  935.678   \n",
       "300         0.875483        1.5963                  939.658   \n",
       "400         0.877512        1.6120                  930.524   \n",
       "500         0.878976        1.5864                  945.514   \n",
       "600         0.880772        1.6062                  933.861   \n",
       "700         0.880042        1.5980                  938.691   \n",
       "800         0.879694        1.5995                  937.795   \n",
       "900         0.879824        1.5994                  937.830   \n",
       "\n",
       "      eval_steps_per_second  train_runtime  train_samples_per_second  \\\n",
       "step                                                                   \n",
       "100                  28.350            NaN                       NaN   \n",
       "200                  29.318            NaN                       NaN   \n",
       "300                  29.443            NaN                       NaN   \n",
       "400                  29.156            NaN                       NaN   \n",
       "500                  29.626            NaN                       NaN   \n",
       "600                  29.261            NaN                       NaN   \n",
       "700                  29.412            NaN                       NaN   \n",
       "800                  29.384            NaN                       NaN   \n",
       "900                  29.385       183.4151                   156.721   \n",
       "\n",
       "      train_steps_per_second    total_flos  train_loss  \n",
       "step                                                    \n",
       "100                      NaN           NaN         NaN  \n",
       "200                      NaN           NaN         NaN  \n",
       "300                      NaN           NaN         NaN  \n",
       "400                      NaN           NaN         NaN  \n",
       "500                      NaN           NaN         NaN  \n",
       "600                      NaN           NaN         NaN  \n",
       "700                      NaN           NaN         NaN  \n",
       "800                      NaN           NaN         NaN  \n",
       "900                    4.907  1.026875e+15    0.555974  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_history = pd.DataFrame(trainer.state.log_history)\n",
    "training_history.groupby(\"step\").first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Loss and Evaluation Metrics over Training Steps"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "data = training_history[[\"loss\", \"eval_loss\", \"step\", f\"eval_{metric_for_best_model}\"]]\n",
    "data.columns = [\"Train. Loss\", \"Eval. Loss\", \"Training Steps\", \"Spearman's ρ\"]\n",
    "data = pd.melt(data, ['Training Steps'])\n",
    "\n",
    "plot = sns.lineplot(data=data, x=\"Training Steps\", y=\"value\", hue=\"variable\", style=\"variable\", markers=True)\n",
    "plot.set_ylabel(\"\")\n",
    "plot.set_ylim((0, plot.get_ylim()[1]))\n",
    "plot.legend(title=\"\")\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "display(Markdown(\"### Loss and Evaluation Metrics over Training Steps\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Best Model performance:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Our Model\" based on google-bert/bert-base-uncased, best performance on validation data.\n",
      "BERT_BASE and BERT_LARGE performance on GLUE testing data as reported in original paper.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Our Model</th>\n",
       "      <th>original BERT_BASE</th>\n",
       "      <th>original BERT_LARGE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>eval_loss</th>\n",
       "      <td>0.569831</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_pearson</th>\n",
       "      <td>0.883817</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_spearmanr</th>\n",
       "      <td>0.880772</td>\n",
       "      <td>0.858</td>\n",
       "      <td>0.865</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Our Model original BERT_BASE original BERT_LARGE\n",
       "eval_loss        0.569831                  -                   -\n",
       "eval_pearson     0.883817                  -                   -\n",
       "eval_spearmanr   0.880772              0.858               0.865"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(Markdown(f\"### Best Model performance:\"))\n",
    "results = pd.DataFrame(\n",
    "    best_model_evaluation.values(),\n",
    "    index=best_model_evaluation.keys(),\n",
    "    columns=[\"Our Model\"],\n",
    ").drop(\n",
    "    # Drop runtime measurements\n",
    "    index=[\"eval_runtime\", \"eval_samples_per_second\", \"eval_steps_per_second\", \"epoch\"]\n",
    ")\n",
    "# Achieved scores from original BERT paper:\n",
    "results[\"original BERT_BASE\"] = [\"-\", \"-\", 0.858]\n",
    "results[\"original BERT_LARGE\"] = [\"-\", \"-\", 0.865]\n",
    "print(f'\"Our Model\" based on {PRE_TRAINED_CHECKPOINT}, best performance on validation data.')\n",
    "print('\"BERT_BASE\" and \"BERT_LARGE\" performance on GLUE testing data as reported in original paper.')\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
