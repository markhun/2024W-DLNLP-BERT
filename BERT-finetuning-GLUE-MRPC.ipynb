{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-Tuning BERT on GLUE - MRPC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From [Microsoft Research Paraphrase Corpus](https://www.microsoft.com/en-us/download/details.aspx?id=52398):\n",
    "\n",
    "A text file containing 5800 pairs of sentences which have been extracted from news sources on the web, along with human annotations indicating whether each pair captures a paraphrase/semantic equivalence relationship. No more than 1 sentence has been extracted from any given news article. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Where to store the huggingface data. On the provided Jupyterlab instance that should be within the shared group folder.\n",
    "os.environ['HF_HOME'] = '../groups/192.039-2024W/bert/huggingface/cache'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from transformers import set_seed\n",
    "\n",
    "# RANDOMNESS SEED\n",
    "SEED = 42\n",
    "set_seed(SEED)\n",
    "\n",
    "# Which dataset to load\n",
    "DATASET_NAME = \"glue\"\n",
    "DATASET_TASK = \"mrpc\"\n",
    "\n",
    "PRE_TRAINED_CHECKPOINT = \"google-bert/bert-base-uncased\"\n",
    "\n",
    "TRAIN_OUTPUT_DIR = (\n",
    "    Path(\"../groups/192.039-2024W/bert\") / \"training\" / f\"{DATASET_NAME}-{DATASET_TASK}\"\n",
    ")\n",
    "\n",
    "BATCH_SIZE = 32  # Original Paper claims to use 32 for GLUE tasks\n",
    "NUM_EPOCHS = 5  # Original Paper claims to use 3 fine-tuning epochs for GLUE tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "GPU used: NVIDIA GeForce RTX 4060 Ti\n",
      "\n",
      "==============NVSMI LOG==============\n",
      "\n",
      "Timestamp                                 : Sat Jan  4 17:27:16 2025\n",
      "Driver Version                            : 550.135\n",
      "CUDA Version                              : 12.4\n",
      "\n",
      "Attached GPUs                             : 1\n",
      "GPU 00000000:07:00.0\n",
      "    FB Memory Usage\n",
      "        Total                             : 16380 MiB\n",
      "        Reserved                          : 307 MiB\n",
      "        Used                              : 3890 MiB\n",
      "        Free                              : 12185 MiB\n",
      "    BAR1 Memory Usage\n",
      "        Total                             : 256 MiB\n",
      "        Used                              : 26 MiB\n",
      "        Free                              : 230 MiB\n",
      "    Conf Compute Protected Memory Usage\n",
      "        Total                             : 0 MiB\n",
      "        Used                              : 0 MiB\n",
      "        Free                              : 0 MiB\n",
      "    Compute Mode                          : Default\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "  device = torch.device(\"cuda\")\n",
    "  device_count = torch.cuda.device_count()\n",
    "  device_name = torch.cuda.get_device_name(0)\n",
    "\n",
    "  print(f\"There are {device_count} GPU(s) available.\")\n",
    "  print(f\"GPU used: {device_name}\")\n",
    "  ! nvidia-smi -q --display=MEMORY,COMPUTE\n",
    "\n",
    "else:\n",
    "  print(\"No GPU available, using CPU.\")\n",
    "  device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the GLUE dataset different tasks have different accessor keys\n",
    "_task_to_keys = {\n",
    "    \"cola\": (\"sentence\", None),\n",
    "    \"mnli\": (\"premise\", \"hypothesis\"),\n",
    "    \"mnli-mm\": (\"premise\", \"hypothesis\"),\n",
    "    \"mrpc\": (\"sentence1\", \"sentence2\"),\n",
    "    \"qnli\": (\"question\", \"sentence\"),\n",
    "    \"qqp\": (\"question1\", \"question2\"),\n",
    "    \"rte\": (\"sentence1\", \"sentence2\"),\n",
    "    \"sst2\": (\"sentence\", None),\n",
    "    \"stsb\": (\"sentence1\", \"sentence2\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
       "        num_rows: 3668\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
       "        num_rows: 408\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
       "        num_rows: 1725\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "dataset = load_dataset(DATASET_NAME, DATASET_TASK)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>label</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>Tibco has used the Rendezvous name since 1994 ...</td>\n",
       "      <td>Tibco has used the Rendezvous name since 1994 ...</td>\n",
       "      <td>1</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2679</th>\n",
       "      <td>Most of the alleged spammers engaged in fraudu...</td>\n",
       "      <td>\" Spam knows no borders , \" said Brad Smith , ...</td>\n",
       "      <td>0</td>\n",
       "      <td>2977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3133</th>\n",
       "      <td>Yesterday , Taiwan reported 35 new infections ...</td>\n",
       "      <td>The island reported another 35 probable cases ...</td>\n",
       "      <td>1</td>\n",
       "      <td>3482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1061</th>\n",
       "      <td>A month ago , the Commerce Department estimate...</td>\n",
       "      <td>A month ago , the Commerce Department said GDP...</td>\n",
       "      <td>1</td>\n",
       "      <td>1187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1091</th>\n",
       "      <td>Gillespie sent a letter to CBS President Lesli...</td>\n",
       "      <td>Republican National Committee Chairman Ed Gill...</td>\n",
       "      <td>0</td>\n",
       "      <td>1220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2230</th>\n",
       "      <td>A New Castle County woman has become the first...</td>\n",
       "      <td>A 62-year-old West Babylon man has contracted ...</td>\n",
       "      <td>0</td>\n",
       "      <td>2483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2287</th>\n",
       "      <td>He admits he occasionally lived the life of a ...</td>\n",
       "      <td>Schwarzenegger has admitted to occasionally li...</td>\n",
       "      <td>1</td>\n",
       "      <td>2544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>U.S. law enforcement officials are sneering at...</td>\n",
       "      <td>U.S. law enforcement officials are sneering at...</td>\n",
       "      <td>1</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>965</th>\n",
       "      <td>He reportedly claims Prime Minister Sir Allan ...</td>\n",
       "      <td>He was reported as saying Prime Minister Sir A...</td>\n",
       "      <td>1</td>\n",
       "      <td>1078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>History will remember the University of Washin...</td>\n",
       "      <td>Dr. Belding Scribner , inventor of a device th...</td>\n",
       "      <td>0</td>\n",
       "      <td>502</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              sentence1  \\\n",
       "179   Tibco has used the Rendezvous name since 1994 ...   \n",
       "2679  Most of the alleged spammers engaged in fraudu...   \n",
       "3133  Yesterday , Taiwan reported 35 new infections ...   \n",
       "1061  A month ago , the Commerce Department estimate...   \n",
       "1091  Gillespie sent a letter to CBS President Lesli...   \n",
       "2230  A New Castle County woman has become the first...   \n",
       "2287  He admits he occasionally lived the life of a ...   \n",
       "149   U.S. law enforcement officials are sneering at...   \n",
       "965   He reportedly claims Prime Minister Sir Allan ...   \n",
       "450   History will remember the University of Washin...   \n",
       "\n",
       "                                              sentence2  label   idx  \n",
       "179   Tibco has used the Rendezvous name since 1994 ...      1   201  \n",
       "2679  \" Spam knows no borders , \" said Brad Smith , ...      0  2977  \n",
       "3133  The island reported another 35 probable cases ...      1  3482  \n",
       "1061  A month ago , the Commerce Department said GDP...      1  1187  \n",
       "1091  Republican National Committee Chairman Ed Gill...      0  1220  \n",
       "2230  A 62-year-old West Babylon man has contracted ...      0  2483  \n",
       "2287  Schwarzenegger has admitted to occasionally li...      1  2544  \n",
       "149   U.S. law enforcement officials are sneering at...      1   167  \n",
       "965   He was reported as saying Prime Minister Sir A...      1  1078  \n",
       "450   Dr. Belding Scribner , inventor of a device th...      0   502  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(dataset[\"train\"]).sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique_lables_in_dataset=array([1, 0])\n",
      "num_labels=2\n"
     ]
    }
   ],
   "source": [
    "unique_lables_in_dataset = pd.DataFrame(dataset[\"train\"])[\"label\"].unique()\n",
    "num_labels = len(unique_lables_in_dataset)\n",
    "\n",
    "print(f\"{unique_lables_in_dataset=}\")\n",
    "print(f\"{num_labels=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(PRE_TRAINED_CHECKPOINT, do_lower_case=\"uncased\" in PRE_TRAINED_CHECKPOINT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BERT has a maximum sequence length of 512. We can check the sequence lengths resulting from tokenizing our dataset to see if our dataset exceeds this restriction of BERT:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length in split='train': 103\n",
      "Max length in split='validation': 86\n",
      "Max length in split='test': 104\n"
     ]
    }
   ],
   "source": [
    "first_sentence_key, second_sentence_key = _task_to_keys[DATASET_TASK]\n",
    "\n",
    "if second_sentence_key == None:  # Simply tokenize sentence\n",
    "\n",
    "    for split in dataset.keys():\n",
    "        max_len = 0\n",
    "        for sentence in dataset[split][first_sentence_key]:\n",
    "            # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
    "            input_ids = tokenizer.encode(sentence, add_special_tokens=True)\n",
    "            \n",
    "            max_len = max(max_len, len(input_ids))\n",
    "        \n",
    "\n",
    "        print(f\"Max length in {split=}: {max_len}\")\n",
    "\n",
    "else:  # Append both sentences via [SEP] and tokenize\n",
    "\n",
    "    for split in dataset.keys():\n",
    "        max_len = 0\n",
    "        for sentence1, sentence2 in zip(dataset[split][first_sentence_key], dataset[split][second_sentence_key]):\n",
    "            # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
    "            input_ids = tokenizer.encode(sentence1, sentence2,  add_special_tokens=True)\n",
    "            \n",
    "            max_len = max(max_len, len(input_ids))\n",
    "        \n",
    "\n",
    "        print(f\"Max length in {split=}: {max_len}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_func(item):\n",
    "    \"\"\"Tokenize passed item. \n",
    "    \n",
    "    Depending on dataset task the passed item will either contain one sentence or two sentences.\n",
    "    In the last case the two sentences will be appended via a [SEP] token.\n",
    "    \"\"\"\n",
    "    if second_sentence_key is None:\n",
    "        return tokenizer(item[first_sentence_key], add_special_tokens=True, truncation=True)\n",
    "    else:\n",
    "        return tokenizer(item[first_sentence_key], item[second_sentence_key], add_special_tokens=True, truncation=True)\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_func, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example of a tokenized dataset item:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence1': ['Amrozi accused his brother , whom he called \" the witness \" , of deliberately distorting his evidence .'],\n",
       " 'sentence2': ['Referring to him as only \" the witness \" , Amrozi accused his brother of deliberately distorting his evidence .'],\n",
       " 'label': [1],\n",
       " 'idx': [0]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence1': ['Amrozi accused his brother , whom he called \" the witness \" , of deliberately distorting his evidence .'],\n",
       " 'sentence2': ['Referring to him as only \" the witness \" , Amrozi accused his brother of deliberately distorting his evidence .'],\n",
       " 'label': [1],\n",
       " 'idx': [0],\n",
       " 'input_ids': [[101,\n",
       "   2572,\n",
       "   3217,\n",
       "   5831,\n",
       "   5496,\n",
       "   2010,\n",
       "   2567,\n",
       "   1010,\n",
       "   3183,\n",
       "   2002,\n",
       "   2170,\n",
       "   1000,\n",
       "   1996,\n",
       "   7409,\n",
       "   1000,\n",
       "   1010,\n",
       "   1997,\n",
       "   9969,\n",
       "   4487,\n",
       "   23809,\n",
       "   3436,\n",
       "   2010,\n",
       "   3350,\n",
       "   1012,\n",
       "   102,\n",
       "   7727,\n",
       "   2000,\n",
       "   2032,\n",
       "   2004,\n",
       "   2069,\n",
       "   1000,\n",
       "   1996,\n",
       "   7409,\n",
       "   1000,\n",
       "   1010,\n",
       "   2572,\n",
       "   3217,\n",
       "   5831,\n",
       "   5496,\n",
       "   2010,\n",
       "   2567,\n",
       "   1997,\n",
       "   9969,\n",
       "   4487,\n",
       "   23809,\n",
       "   3436,\n",
       "   2010,\n",
       "   3350,\n",
       "   1012,\n",
       "   102]],\n",
       " 'token_type_ids': [[0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1]],\n",
       " 'attention_mask': [[1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1]]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset[\"train\"][:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenization added the `input_ids` field, which contains the tokenized sentence with a `[CLS]`(101) and two `[SEP]`(102) tokens added. A `token_type_ids` field which indicates first and second portion of the inputs, if necessary. And an `attention_mask` for the given input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with Padding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Huggingface's `transformers` library provides a `DataCollatorWithPadding` class, which allows us to use dynamic padding.  \n",
    "Dynamic padding will add `[PAD]` tokens to the length of the longest sequence within a batch, instead of padding to the maximum sequence length within the entire dataset.  \n",
    "This will avoid unnecessary padding and therefore improve execution efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>2572</td>\n",
       "      <td>3217</td>\n",
       "      <td>5831</td>\n",
       "      <td>5496</td>\n",
       "      <td>2010</td>\n",
       "      <td>2567</td>\n",
       "      <td>1010</td>\n",
       "      <td>3183</td>\n",
       "      <td>2002</td>\n",
       "      <td>...</td>\n",
       "      <td>102.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101</td>\n",
       "      <td>9805</td>\n",
       "      <td>3540</td>\n",
       "      <td>11514</td>\n",
       "      <td>2050</td>\n",
       "      <td>3079</td>\n",
       "      <td>11282</td>\n",
       "      <td>2243</td>\n",
       "      <td>1005</td>\n",
       "      <td>1055</td>\n",
       "      <td>...</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>1002.0</td>\n",
       "      <td>1015.0</td>\n",
       "      <td>1012.0</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>4551.0</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>2687.0</td>\n",
       "      <td>1012.0</td>\n",
       "      <td>102.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101</td>\n",
       "      <td>2027</td>\n",
       "      <td>2018</td>\n",
       "      <td>2405</td>\n",
       "      <td>2019</td>\n",
       "      <td>15147</td>\n",
       "      <td>2006</td>\n",
       "      <td>1996</td>\n",
       "      <td>4274</td>\n",
       "      <td>2006</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0     1     2      3     4      5      6     7     8     9   ...      49  \\\n",
       "0  101  2572  3217   5831  5496   2010   2567  1010  3183  2002  ...   102.0   \n",
       "1  101  9805  3540  11514  2050   3079  11282  2243  1005  1055  ...  2005.0   \n",
       "2  101  2027  2018   2405  2019  15147   2006  1996  4274  2006  ...     NaN   \n",
       "\n",
       "       50      51      52      53      54      55      56      57     58  \n",
       "0     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN    NaN  \n",
       "1  1002.0  1015.0  1012.0  1022.0  4551.0  1999.0  2687.0  1012.0  102.0  \n",
       "2     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN    NaN  \n",
       "\n",
       "[3 rows x 59 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "# Example: Select a few samples from the training set\n",
    "samples = tokenized_dataset[\"train\"][:3]\n",
    "samples = {k: v for k, v in samples.items() if k not in [\"idx\", first_sentence_key, second_sentence_key]}  # Drop `idx` and `sentence` columns, as DataCollator can't process those.\n",
    "pd.DataFrame(samples[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>2572</td>\n",
       "      <td>3217</td>\n",
       "      <td>5831</td>\n",
       "      <td>5496</td>\n",
       "      <td>2010</td>\n",
       "      <td>2567</td>\n",
       "      <td>1010</td>\n",
       "      <td>3183</td>\n",
       "      <td>2002</td>\n",
       "      <td>...</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101</td>\n",
       "      <td>9805</td>\n",
       "      <td>3540</td>\n",
       "      <td>11514</td>\n",
       "      <td>2050</td>\n",
       "      <td>3079</td>\n",
       "      <td>11282</td>\n",
       "      <td>2243</td>\n",
       "      <td>1005</td>\n",
       "      <td>1055</td>\n",
       "      <td>...</td>\n",
       "      <td>2005</td>\n",
       "      <td>1002</td>\n",
       "      <td>1015</td>\n",
       "      <td>1012</td>\n",
       "      <td>1022</td>\n",
       "      <td>4551</td>\n",
       "      <td>1999</td>\n",
       "      <td>2687</td>\n",
       "      <td>1012</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101</td>\n",
       "      <td>2027</td>\n",
       "      <td>2018</td>\n",
       "      <td>2405</td>\n",
       "      <td>2019</td>\n",
       "      <td>15147</td>\n",
       "      <td>2006</td>\n",
       "      <td>1996</td>\n",
       "      <td>4274</td>\n",
       "      <td>2006</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0     1     2      3     4      5      6     7     8     9   ...    49  \\\n",
       "0  101  2572  3217   5831  5496   2010   2567  1010  3183  2002  ...   102   \n",
       "1  101  9805  3540  11514  2050   3079  11282  2243  1005  1055  ...  2005   \n",
       "2  101  2027  2018   2405  2019  15147   2006  1996  4274  2006  ...     0   \n",
       "\n",
       "     50    51    52    53    54    55    56    57   58  \n",
       "0     0     0     0     0     0     0     0     0    0  \n",
       "1  1002  1015  1012  1022  4551  1999  2687  1012  102  \n",
       "2     0     0     0     0     0     0     0     0    0  \n",
       "\n",
       "[3 rows x 59 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply padding using data_collator\n",
    "batch = data_collator(samples)\n",
    "pd.DataFrame(batch[\"input_ids\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that `data_collator` will insert `[PAD]` (0) tokens to the maximum length of the passed batch of data items."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The GLUE dataset specifies one or more evaluation metrics depending on the selected task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EvaluationModule(name: \"glue\", module_type: \"metric\", features: {'predictions': Value(dtype='int64', id=None), 'references': Value(dtype='int64', id=None)}, usage: \"\"\"\n",
       "Compute GLUE evaluation metric associated to each GLUE dataset.\n",
       "Args:\n",
       "    predictions: list of predictions to score.\n",
       "        Each translation should be tokenized into a list of tokens.\n",
       "    references: list of lists of references for each translation.\n",
       "        Each reference should be tokenized into a list of tokens.\n",
       "Returns: depending on the GLUE subset, one or several of:\n",
       "    \"accuracy\": Accuracy\n",
       "    \"f1\": F1 score\n",
       "    \"pearson\": Pearson Correlation\n",
       "    \"spearmanr\": Spearman Correlation\n",
       "    \"matthews_correlation\": Matthew Correlation\n",
       "Examples:\n",
       "\n",
       "    >>> glue_metric = evaluate.load('glue', 'sst2')  # 'sst2' or any of [\"mnli\", \"mnli_mismatched\", \"mnli_matched\", \"qnli\", \"rte\", \"wnli\", \"hans\"]\n",
       "    >>> references = [0, 1]\n",
       "    >>> predictions = [0, 1]\n",
       "    >>> results = glue_metric.compute(predictions=predictions, references=references)\n",
       "    >>> print(results)\n",
       "    {'accuracy': 1.0}\n",
       "\n",
       "    >>> glue_metric = evaluate.load('glue', 'mrpc')  # 'mrpc' or 'qqp'\n",
       "    >>> references = [0, 1]\n",
       "    >>> predictions = [0, 1]\n",
       "    >>> results = glue_metric.compute(predictions=predictions, references=references)\n",
       "    >>> print(results)\n",
       "    {'accuracy': 1.0, 'f1': 1.0}\n",
       "\n",
       "    >>> glue_metric = evaluate.load('glue', 'stsb')\n",
       "    >>> references = [0., 1., 2., 3., 4., 5.]\n",
       "    >>> predictions = [0., 1., 2., 3., 4., 5.]\n",
       "    >>> results = glue_metric.compute(predictions=predictions, references=references)\n",
       "    >>> print({\"pearson\": round(results[\"pearson\"], 2), \"spearmanr\": round(results[\"spearmanr\"], 2)})\n",
       "    {'pearson': 1.0, 'spearmanr': 1.0}\n",
       "\n",
       "    >>> glue_metric = evaluate.load('glue', 'cola')\n",
       "    >>> references = [0, 1]\n",
       "    >>> predictions = [0, 1]\n",
       "    >>> results = glue_metric.compute(predictions=predictions, references=references)\n",
       "    >>> print(results)\n",
       "    {'matthews_correlation': 1.0}\n",
       "\"\"\", stored examples: 0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(DATASET_NAME, DATASET_TASK)\n",
    "metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on the selected GLUE task we optimize for different evaluation metrics. See BERT paper p.6:\n",
    "\n",
    "> F1 scores are reported for QQP and MRPC, Spearman correlations are reported for STS-B, and accuracy scores are reported for the other tasks. We exclude entries that use BERT as one of their components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "_task_to_metric = {\n",
    "    \"cola\": \"matthews_correlation\",\n",
    "    \"mnli\": \"accuracy\",\n",
    "    \"mnli-mm\": \"accuracy\",\n",
    "    \"mrpc\": \"f1\",\n",
    "    \"qnli\": \"accuracy\",\n",
    "    \"qqp\": \"f1\",\n",
    "    \"rte\": \"accuracy\",\n",
    "    \"sst2\": \"accuracy\",\n",
    "    \"stsb\": \"spearman\",\n",
    "}\n",
    "\n",
    "metric_for_best_model = _task_to_metric[DATASET_TASK]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We will use \"['accuracy', 'f1']\" as an evaluation metric for the task mrpc\n"
     ]
    }
   ],
   "source": [
    "def get_metric_name_for_specific_task():\n",
    "    \"\"\"Helper function to derive the evaluation metric name for the specified GLUE task.\n",
    "\n",
    "    The tasks specified by the GLUE benchmark use different evaluation metrics.\n",
    "    Unfortunatly there is no easy way to derive there name after loading the corresponding metric function via HuggingFace's `evaluate` library.\n",
    "    However we can simply do a \"trial run\" and expect the name key of its output.\n",
    "    \"\"\"\n",
    "    output = metric.compute(\n",
    "        predictions=[1, 0], references=[1, 1]\n",
    "    )  # dummy input - we just want to inspect the returned dictionary.\n",
    "    metric_names = output.keys()  # simply gets first key of output\n",
    "    \n",
    "    return list(metric_names)\n",
    "\n",
    "\n",
    "metric_names = get_metric_name_for_specific_task()\n",
    "print(f'We will use \"{metric_names}\" as an evaluation metric for the task {DATASET_TASK}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert metric_for_best_model in metric_names, \"Metric to optimize for not found in evaluation metrics provided by GLUE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    PRE_TRAINED_CHECKPOINT,\n",
    "    num_labels=num_labels,\n",
    "    torch_dtype=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_arguments = TrainingArguments(\n",
    "    output_dir=TRAIN_OUTPUT_DIR,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=100,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=100,\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=100,\n",
    "    num_train_epochs=NUM_EPOCHS,\n",
    "    learning_rate=2e-5,  # Original paper uses best out of  5e-5, 4e-5, 3e-5, and 2e-5\n",
    "    weight_decay=0.01,  # Original paper uses 0.01 on pre-training\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=metric_for_best_model,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    if DATASET_TASK != \"stsb\":\n",
    "        predictions = np.argmax(predictions, axis=1)\n",
    "    else:\n",
    "        predictions = predictions[:, 0]\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "validation_key = \"validation_mismatched\" if DATASET_TASK == \"mnli-mm\" else \"validation_matched\" if DATASET_TASK == \"mnli\" else \"validation\"\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_arguments,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[validation_key],\n",
    "    data_collator=data_collator,\n",
    "    processing_class=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- training_arguments.output_dir='../groups/192.039-2024W/bert/training/glue-mrpc'\n",
      "--- training_arguments.metric_for_best_model='f1'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83f283b6358e41b7b732c18b18ae36a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/575 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.565, 'grad_norm': 4.123088836669922, 'learning_rate': 1.6521739130434785e-05, 'epoch': 0.87}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdc1765f383e4753a41c358f6385d21c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4811389744281769, 'eval_accuracy': 0.7990196078431373, 'eval_f1': 0.8673139158576052, 'eval_runtime': 0.6907, 'eval_samples_per_second': 590.705, 'eval_steps_per_second': 18.821, 'epoch': 0.87}\n",
      "{'loss': 0.3849, 'grad_norm': 6.8734354972839355, 'learning_rate': 1.3043478260869566e-05, 'epoch': 1.74}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f41e8fee71874794818fed84ba1f378b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4041897654533386, 'eval_accuracy': 0.8235294117647058, 'eval_f1': 0.8795986622073578, 'eval_runtime': 0.6904, 'eval_samples_per_second': 590.928, 'eval_steps_per_second': 18.829, 'epoch': 1.74}\n",
      "{'loss': 0.26, 'grad_norm': 7.530885219573975, 'learning_rate': 9.565217391304349e-06, 'epoch': 2.61}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0225f8e9712e40cf9315bca804ba8b7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.36670538783073425, 'eval_accuracy': 0.8578431372549019, 'eval_f1': 0.8964285714285715, 'eval_runtime': 0.6968, 'eval_samples_per_second': 585.562, 'eval_steps_per_second': 18.658, 'epoch': 2.61}\n",
      "{'loss': 0.1666, 'grad_norm': 6.01115083694458, 'learning_rate': 6.086956521739132e-06, 'epoch': 3.48}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "478aa5a436e64f57b6571608243561a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4313111901283264, 'eval_accuracy': 0.8529411764705882, 'eval_f1': 0.8972602739726028, 'eval_runtime': 0.6963, 'eval_samples_per_second': 585.958, 'eval_steps_per_second': 18.67, 'epoch': 3.48}\n",
      "{'loss': 0.1255, 'grad_norm': 11.058963775634766, 'learning_rate': 2.6086956521739132e-06, 'epoch': 4.35}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22cce7189da94d728cffa46621e03e92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.45862698554992676, 'eval_accuracy': 0.8504901960784313, 'eval_f1': 0.8964346349745331, 'eval_runtime': 0.6931, 'eval_samples_per_second': 588.696, 'eval_steps_per_second': 18.757, 'epoch': 4.35}\n",
      "{'train_runtime': 124.6337, 'train_samples_per_second': 147.151, 'train_steps_per_second': 4.614, 'train_loss': 0.2717412592017132, 'epoch': 5.0}\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "print(f\"--- {training_arguments.output_dir=}\")\n",
    "print(f\"--- {training_arguments.metric_for_best_model=}\")\n",
    "training_summary = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=575, training_loss=0.2717412592017132, metrics={'train_runtime': 124.6337, 'train_samples_per_second': 147.151, 'train_steps_per_second': 4.614, 'total_flos': 752339340585360.0, 'train_loss': 0.2717412592017132, 'epoch': 5.0})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can call `trainer.evaluate()` to check that the `trainer` instance did indeed reload the model checkpoint with the highest evaluation score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0665dacd62fb472798210ab2b3e6898d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.4313111901283264,\n",
       " 'eval_accuracy': 0.8529411764705882,\n",
       " 'eval_f1': 0.8972602739726028,\n",
       " 'eval_runtime': 0.7164,\n",
       " 'eval_samples_per_second': 569.497,\n",
       " 'eval_steps_per_second': 18.146,\n",
       " 'epoch': 5.0}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_evaluation = trainer.evaluate()\n",
    "best_model_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>grad_norm</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>epoch</th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>eval_accuracy</th>\n",
       "      <th>eval_f1</th>\n",
       "      <th>eval_runtime</th>\n",
       "      <th>eval_samples_per_second</th>\n",
       "      <th>eval_steps_per_second</th>\n",
       "      <th>train_runtime</th>\n",
       "      <th>train_samples_per_second</th>\n",
       "      <th>train_steps_per_second</th>\n",
       "      <th>total_flos</th>\n",
       "      <th>train_loss</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>step</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.5650</td>\n",
       "      <td>4.123089</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.481139</td>\n",
       "      <td>0.799020</td>\n",
       "      <td>0.867314</td>\n",
       "      <td>0.6907</td>\n",
       "      <td>590.705</td>\n",
       "      <td>18.821</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>0.3849</td>\n",
       "      <td>6.873435</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>1.739130</td>\n",
       "      <td>0.404190</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.879599</td>\n",
       "      <td>0.6904</td>\n",
       "      <td>590.928</td>\n",
       "      <td>18.829</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>0.2600</td>\n",
       "      <td>7.530885</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>2.608696</td>\n",
       "      <td>0.366705</td>\n",
       "      <td>0.857843</td>\n",
       "      <td>0.896429</td>\n",
       "      <td>0.6968</td>\n",
       "      <td>585.562</td>\n",
       "      <td>18.658</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>0.1666</td>\n",
       "      <td>6.011151</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>3.478261</td>\n",
       "      <td>0.431311</td>\n",
       "      <td>0.852941</td>\n",
       "      <td>0.897260</td>\n",
       "      <td>0.6963</td>\n",
       "      <td>585.958</td>\n",
       "      <td>18.670</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>0.1255</td>\n",
       "      <td>11.058964</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>4.347826</td>\n",
       "      <td>0.458627</td>\n",
       "      <td>0.850490</td>\n",
       "      <td>0.896435</td>\n",
       "      <td>0.6931</td>\n",
       "      <td>588.696</td>\n",
       "      <td>18.757</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.431311</td>\n",
       "      <td>0.852941</td>\n",
       "      <td>0.897260</td>\n",
       "      <td>0.7164</td>\n",
       "      <td>569.497</td>\n",
       "      <td>18.146</td>\n",
       "      <td>124.6337</td>\n",
       "      <td>147.151</td>\n",
       "      <td>4.614</td>\n",
       "      <td>7.523393e+14</td>\n",
       "      <td>0.271741</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        loss  grad_norm  learning_rate     epoch  eval_loss  eval_accuracy  \\\n",
       "step                                                                         \n",
       "100   0.5650   4.123089       0.000017  0.869565   0.481139       0.799020   \n",
       "200   0.3849   6.873435       0.000013  1.739130   0.404190       0.823529   \n",
       "300   0.2600   7.530885       0.000010  2.608696   0.366705       0.857843   \n",
       "400   0.1666   6.011151       0.000006  3.478261   0.431311       0.852941   \n",
       "500   0.1255  11.058964       0.000003  4.347826   0.458627       0.850490   \n",
       "575      NaN        NaN            NaN  5.000000   0.431311       0.852941   \n",
       "\n",
       "       eval_f1  eval_runtime  eval_samples_per_second  eval_steps_per_second  \\\n",
       "step                                                                           \n",
       "100   0.867314        0.6907                  590.705                 18.821   \n",
       "200   0.879599        0.6904                  590.928                 18.829   \n",
       "300   0.896429        0.6968                  585.562                 18.658   \n",
       "400   0.897260        0.6963                  585.958                 18.670   \n",
       "500   0.896435        0.6931                  588.696                 18.757   \n",
       "575   0.897260        0.7164                  569.497                 18.146   \n",
       "\n",
       "      train_runtime  train_samples_per_second  train_steps_per_second  \\\n",
       "step                                                                    \n",
       "100             NaN                       NaN                     NaN   \n",
       "200             NaN                       NaN                     NaN   \n",
       "300             NaN                       NaN                     NaN   \n",
       "400             NaN                       NaN                     NaN   \n",
       "500             NaN                       NaN                     NaN   \n",
       "575        124.6337                   147.151                   4.614   \n",
       "\n",
       "        total_flos  train_loss  \n",
       "step                            \n",
       "100            NaN         NaN  \n",
       "200            NaN         NaN  \n",
       "300            NaN         NaN  \n",
       "400            NaN         NaN  \n",
       "500            NaN         NaN  \n",
       "575   7.523393e+14    0.271741  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_history = pd.DataFrame(trainer.state.log_history)\n",
    "training_history.groupby(\"step\").first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Loss and Evaluation Metrics over Training Steps"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "data = training_history[[\"loss\", \"eval_loss\", \"step\", f\"eval_{metric_for_best_model}\"]]\n",
    "data.columns = [\"Train. Loss\", \"Eval. Loss\", \"Training Steps\", \"F1\"]\n",
    "data = pd.melt(data, ['Training Steps'])\n",
    "\n",
    "plot = sns.lineplot(data=data, x=\"Training Steps\", y=\"value\", hue=\"variable\", style=\"variable\", markers=True)\n",
    "plot.set_ylabel(\"\")\n",
    "plot.set_ylim((0, plot.get_ylim()[1]))\n",
    "plot.legend(title=\"\")\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "display(Markdown(\"### Loss and Evaluation Metrics over Training Steps\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Best Model performance:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Our Model\" based on google-bert/bert-base-uncased\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Our Model</th>\n",
       "      <th>original BERT_BASE</th>\n",
       "      <th>original BERT_LARGE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>eval_loss</th>\n",
       "      <td>0.431311</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_accuracy</th>\n",
       "      <td>0.852941</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_f1</th>\n",
       "      <td>0.897260</td>\n",
       "      <td>0.889</td>\n",
       "      <td>0.893</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Our Model original BERT_BASE original BERT_LARGE\n",
       "eval_loss       0.431311                  -                   -\n",
       "eval_accuracy   0.852941                  -                   -\n",
       "eval_f1         0.897260              0.889               0.893"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(Markdown(f\"### Best Model performance:\"))\n",
    "results = pd.DataFrame(\n",
    "    best_model_evaluation.values(),\n",
    "    index=best_model_evaluation.keys(),\n",
    "    columns=[\"Our Model\"],\n",
    ").drop(\n",
    "    # Drop runtime measurements\n",
    "    index=[\"eval_runtime\", \"eval_samples_per_second\", \"eval_steps_per_second\", \"epoch\"]\n",
    ")\n",
    "# Achieved scores from original BERT paper:\n",
    "results[\"original BERT_BASE\"] = [\"-\", \"-\", 0.889]\n",
    "results[\"original BERT_LARGE\"] = [\"-\", \"-\", 0.893]\n",
    "print(f'\"Our Model\" based on {PRE_TRAINED_CHECKPOINT}')\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
