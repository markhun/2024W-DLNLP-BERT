{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-Tuning BERT on GLUE - RTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From [ACLweb](https://aclweb.org/aclwiki/Recognizing_Textual_Entailment):\n",
    "\n",
    "Textual Entailment Recognition has been proposed recently as a generic task that captures major semantic inference needs across many NLP applications, such as Question Answering, Information Retrieval, Information Extraction, and Text Summarization. This task requires to recognize, given two text fragments, whether the meaning of one text is entailed (can be inferred) from the other text. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Where to store the huggingface data. On the provided Jupyterlab instance that should be within the shared group folder.\n",
    "os.environ['HF_HOME'] = '../groups/192.039-2024W/bert/huggingface/cache'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from transformers import set_seed\n",
    "\n",
    "# RANDOMNESS SEED\n",
    "SEED = 21\n",
    "set_seed(SEED)\n",
    "\n",
    "# Which dataset to load\n",
    "DATASET_NAME = \"glue\"\n",
    "DATASET_TASK = \"rte\"\n",
    "\n",
    "PRE_TRAINED_CHECKPOINT = \"google-bert/bert-base-uncased\"\n",
    "\n",
    "TRAIN_OUTPUT_DIR = (\n",
    "    Path(\"../groups/192.039-2024W/bert\") / \"training\" / f\"{DATASET_NAME}-{DATASET_TASK}\"\n",
    ")\n",
    "\n",
    "BATCH_SIZE = 32  # Original Paper claims to use 32 for GLUE tasks\n",
    "NUM_EPOCHS = 7  # Original Paper claims to use 3 fine-tuning epochs for GLUE tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "GPU used: NVIDIA GeForce RTX 4060 Ti\n",
      "\n",
      "==============NVSMI LOG==============\n",
      "\n",
      "Timestamp                                 : Sun Jan  5 11:36:36 2025\n",
      "Driver Version                            : 550.135\n",
      "CUDA Version                              : 12.4\n",
      "\n",
      "Attached GPUs                             : 1\n",
      "GPU 00000000:07:00.0\n",
      "    FB Memory Usage\n",
      "        Total                             : 16380 MiB\n",
      "        Reserved                          : 307 MiB\n",
      "        Used                              : 1429 MiB\n",
      "        Free                              : 14646 MiB\n",
      "    BAR1 Memory Usage\n",
      "        Total                             : 256 MiB\n",
      "        Used                              : 25 MiB\n",
      "        Free                              : 231 MiB\n",
      "    Conf Compute Protected Memory Usage\n",
      "        Total                             : 0 MiB\n",
      "        Used                              : 0 MiB\n",
      "        Free                              : 0 MiB\n",
      "    Compute Mode                          : Default\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "  device = torch.device(\"cuda\")\n",
    "  device_count = torch.cuda.device_count()\n",
    "  device_name = torch.cuda.get_device_name(0)\n",
    "\n",
    "  print(f\"There are {device_count} GPU(s) available.\")\n",
    "  print(f\"GPU used: {device_name}\")\n",
    "  ! nvidia-smi -q --display=MEMORY,COMPUTE\n",
    "\n",
    "else:\n",
    "  print(\"No GPU available, using CPU.\")\n",
    "  device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the GLUE dataset different tasks have different accessor keys\n",
    "_task_to_keys = {\n",
    "    \"cola\": (\"sentence\", None),\n",
    "    \"mnli\": (\"premise\", \"hypothesis\"),\n",
    "    \"mnli-mm\": (\"premise\", \"hypothesis\"),\n",
    "    \"mrpc\": (\"sentence1\", \"sentence2\"),\n",
    "    \"qnli\": (\"question\", \"sentence\"),\n",
    "    \"qqp\": (\"question1\", \"question2\"),\n",
    "    \"rte\": (\"sentence1\", \"sentence2\"),\n",
    "    \"sst2\": (\"sentence\", None),\n",
    "    \"stsb\": (\"sentence1\", \"sentence2\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
       "        num_rows: 2490\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
       "        num_rows: 277\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
       "        num_rows: 3000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "dataset = load_dataset(DATASET_NAME, DATASET_TASK)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>label</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1524</th>\n",
       "      <td>The widow of John Lennon, Yoko Ono, may take l...</td>\n",
       "      <td>Yoko Ono is John Lennon's widow.</td>\n",
       "      <td>0</td>\n",
       "      <td>1524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>Swiss police confirmed Thursday that cult lead...</td>\n",
       "      <td>Luc Jouret was the leader of the Order of the ...</td>\n",
       "      <td>1</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1410</th>\n",
       "      <td>Scientists had thought all gamma-ray bursts ha...</td>\n",
       "      <td>The scientists had thought that all explosions...</td>\n",
       "      <td>1</td>\n",
       "      <td>1410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1532</th>\n",
       "      <td>Shelby Foote, author of the acclaimed three vo...</td>\n",
       "      <td>The Civil War: A Narrative is a book written b...</td>\n",
       "      <td>0</td>\n",
       "      <td>1532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>826</th>\n",
       "      <td>Valero Energy Corp., on Monday, said it found ...</td>\n",
       "      <td>Valero Energy Corp. caused damages to Port Art...</td>\n",
       "      <td>1</td>\n",
       "      <td>826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853</th>\n",
       "      <td>Hurricane Katrina petroleum-supply outlook imp...</td>\n",
       "      <td>Offers by individual European governments, inv...</td>\n",
       "      <td>0</td>\n",
       "      <td>853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1739</th>\n",
       "      <td>The launch of France's new 24 hour TV news cha...</td>\n",
       "      <td>France24 is a French TV Channel.</td>\n",
       "      <td>0</td>\n",
       "      <td>1739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1388</th>\n",
       "      <td>The Sears Tower in Chicago, finished in 1974, ...</td>\n",
       "      <td>The Sears Tower has 110 stories.</td>\n",
       "      <td>0</td>\n",
       "      <td>1388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Most people are familiar with the idea of St. ...</td>\n",
       "      <td>Robots are used to find missing victims.</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>938</th>\n",
       "      <td>Co-producing the film is Happy Madison, the co...</td>\n",
       "      <td>Happy Madison works for the company owned by S...</td>\n",
       "      <td>1</td>\n",
       "      <td>938</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              sentence1  \\\n",
       "1524  The widow of John Lennon, Yoko Ono, may take l...   \n",
       "127   Swiss police confirmed Thursday that cult lead...   \n",
       "1410  Scientists had thought all gamma-ray bursts ha...   \n",
       "1532  Shelby Foote, author of the acclaimed three vo...   \n",
       "826   Valero Energy Corp., on Monday, said it found ...   \n",
       "853   Hurricane Katrina petroleum-supply outlook imp...   \n",
       "1739  The launch of France's new 24 hour TV news cha...   \n",
       "1388  The Sears Tower in Chicago, finished in 1974, ...   \n",
       "72    Most people are familiar with the idea of St. ...   \n",
       "938   Co-producing the film is Happy Madison, the co...   \n",
       "\n",
       "                                              sentence2  label   idx  \n",
       "1524                   Yoko Ono is John Lennon's widow.      0  1524  \n",
       "127   Luc Jouret was the leader of the Order of the ...      1   127  \n",
       "1410  The scientists had thought that all explosions...      1  1410  \n",
       "1532  The Civil War: A Narrative is a book written b...      0  1532  \n",
       "826   Valero Energy Corp. caused damages to Port Art...      1   826  \n",
       "853   Offers by individual European governments, inv...      0   853  \n",
       "1739                   France24 is a French TV Channel.      0  1739  \n",
       "1388                   The Sears Tower has 110 stories.      0  1388  \n",
       "72             Robots are used to find missing victims.      0    72  \n",
       "938   Happy Madison works for the company owned by S...      1   938  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(dataset[\"train\"]).sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique_lables_in_dataset=array([1, 0])\n",
      "num_labels=2\n"
     ]
    }
   ],
   "source": [
    "unique_lables_in_dataset = pd.DataFrame(dataset[\"train\"])[\"label\"].unique()\n",
    "num_labels = len(unique_lables_in_dataset)\n",
    "\n",
    "print(f\"{unique_lables_in_dataset=}\")\n",
    "print(f\"{num_labels=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(PRE_TRAINED_CHECKPOINT, do_lower_case=\"uncased\" in PRE_TRAINED_CHECKPOINT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BERT has a maximum sequence length of 512. We can check the sequence lengths resulting from tokenizing our dataset to see if our dataset exceeds this restriction of BERT:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length in split='train': 289\n",
      "Max length in split='validation': 253\n",
      "Max length in split='test': 252\n"
     ]
    }
   ],
   "source": [
    "first_sentence_key, second_sentence_key = _task_to_keys[DATASET_TASK]\n",
    "\n",
    "if second_sentence_key == None:  # Simply tokenize sentence\n",
    "\n",
    "    for split in dataset.keys():\n",
    "        max_len = 0\n",
    "        for sentence in dataset[split][first_sentence_key]:\n",
    "            # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
    "            input_ids = tokenizer.encode(sentence, add_special_tokens=True)\n",
    "            \n",
    "            max_len = max(max_len, len(input_ids))\n",
    "        \n",
    "\n",
    "        print(f\"Max length in {split=}: {max_len}\")\n",
    "\n",
    "else:  # Append both sentences via [SEP] and tokenize\n",
    "\n",
    "    for split in dataset.keys():\n",
    "        max_len = 0\n",
    "        for sentence1, sentence2 in zip(dataset[split][first_sentence_key], dataset[split][second_sentence_key]):\n",
    "            # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
    "            input_ids = tokenizer.encode(sentence1, sentence2,  add_special_tokens=True)\n",
    "            \n",
    "            max_len = max(max_len, len(input_ids))\n",
    "        \n",
    "\n",
    "        print(f\"Max length in {split=}: {max_len}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_func(item):\n",
    "    \"\"\"Tokenize passed item. \n",
    "    \n",
    "    Depending on dataset task the passed item will either contain one sentence or two sentences.\n",
    "    In the last case the two sentences will be appended via a [SEP] token.\n",
    "    \"\"\"\n",
    "    if second_sentence_key is None:\n",
    "        return tokenizer(item[first_sentence_key], add_special_tokens=True, truncation=True)\n",
    "    else:\n",
    "        return tokenizer(item[first_sentence_key], item[second_sentence_key], add_special_tokens=True, truncation=True)\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_func, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example of a tokenized dataset item:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence1': ['No Weapons of Mass Destruction Found in Iraq Yet.'],\n",
       " 'sentence2': ['Weapons of Mass Destruction Found in Iraq.'],\n",
       " 'label': [1],\n",
       " 'idx': [0]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence1': ['No Weapons of Mass Destruction Found in Iraq Yet.'],\n",
       " 'sentence2': ['Weapons of Mass Destruction Found in Iraq.'],\n",
       " 'label': [1],\n",
       " 'idx': [0],\n",
       " 'input_ids': [[101,\n",
       "   2053,\n",
       "   4255,\n",
       "   1997,\n",
       "   3742,\n",
       "   6215,\n",
       "   2179,\n",
       "   1999,\n",
       "   5712,\n",
       "   2664,\n",
       "   1012,\n",
       "   102,\n",
       "   4255,\n",
       "   1997,\n",
       "   3742,\n",
       "   6215,\n",
       "   2179,\n",
       "   1999,\n",
       "   5712,\n",
       "   1012,\n",
       "   102]],\n",
       " 'token_type_ids': [[0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1]],\n",
       " 'attention_mask': [[1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1]]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset[\"train\"][:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenization added the `input_ids` field, which contains the tokenized sentence with a `[CLS]`(101) and two `[SEP]`(102) tokens added. A `token_type_ids` field which indicates first and second portion of the inputs, if necessary. And an `attention_mask` for the given input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with Padding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Huggingface's `transformers` library provides a `DataCollatorWithPadding` class, which allows us to use dynamic padding.  \n",
    "Dynamic padding will add `[PAD]` tokens to the length of the longest sequence within a batch, instead of padding to the maximum sequence length within the entire dataset.  \n",
    "This will avoid unnecessary padding and therefore improve execution efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>2053</td>\n",
       "      <td>4255</td>\n",
       "      <td>1997</td>\n",
       "      <td>3742</td>\n",
       "      <td>6215</td>\n",
       "      <td>2179</td>\n",
       "      <td>1999</td>\n",
       "      <td>5712</td>\n",
       "      <td>2664</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101</td>\n",
       "      <td>1037</td>\n",
       "      <td>2173</td>\n",
       "      <td>1997</td>\n",
       "      <td>14038</td>\n",
       "      <td>1010</td>\n",
       "      <td>2044</td>\n",
       "      <td>4831</td>\n",
       "      <td>2198</td>\n",
       "      <td>2703</td>\n",
       "      <td>...</td>\n",
       "      <td>2277.0</td>\n",
       "      <td>1012.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101</td>\n",
       "      <td>2014</td>\n",
       "      <td>3401</td>\n",
       "      <td>13876</td>\n",
       "      <td>2378</td>\n",
       "      <td>2001</td>\n",
       "      <td>2525</td>\n",
       "      <td>4844</td>\n",
       "      <td>2000</td>\n",
       "      <td>7438</td>\n",
       "      <td>...</td>\n",
       "      <td>2378.0</td>\n",
       "      <td>2064.0</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>2109.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>7438.0</td>\n",
       "      <td>7388.0</td>\n",
       "      <td>4456.0</td>\n",
       "      <td>1012.0</td>\n",
       "      <td>102.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0     1     2      3      4     5     6     7     8     9   ...      49  \\\n",
       "0  101  2053  4255   1997   3742  6215  2179  1999  5712  2664  ...     NaN   \n",
       "1  101  1037  2173   1997  14038  1010  2044  4831  2198  2703  ...  2277.0   \n",
       "2  101  2014  3401  13876   2378  2001  2525  4844  2000  7438  ...  2378.0   \n",
       "\n",
       "       50      51      52      53      54      55      56      57     58  \n",
       "0     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN    NaN  \n",
       "1  1012.0   102.0     NaN     NaN     NaN     NaN     NaN     NaN    NaN  \n",
       "2  2064.0  2022.0  2109.0  2000.0  7438.0  7388.0  4456.0  1012.0  102.0  \n",
       "\n",
       "[3 rows x 59 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "# Example: Select a few samples from the training set\n",
    "samples = tokenized_dataset[\"train\"][:3]\n",
    "samples = {k: v for k, v in samples.items() if k not in [\"idx\", first_sentence_key, second_sentence_key]}  # Drop `idx` and `sentence` columns, as DataCollator can't process those.\n",
    "pd.DataFrame(samples[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>2053</td>\n",
       "      <td>4255</td>\n",
       "      <td>1997</td>\n",
       "      <td>3742</td>\n",
       "      <td>6215</td>\n",
       "      <td>2179</td>\n",
       "      <td>1999</td>\n",
       "      <td>5712</td>\n",
       "      <td>2664</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101</td>\n",
       "      <td>1037</td>\n",
       "      <td>2173</td>\n",
       "      <td>1997</td>\n",
       "      <td>14038</td>\n",
       "      <td>1010</td>\n",
       "      <td>2044</td>\n",
       "      <td>4831</td>\n",
       "      <td>2198</td>\n",
       "      <td>2703</td>\n",
       "      <td>...</td>\n",
       "      <td>2277</td>\n",
       "      <td>1012</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101</td>\n",
       "      <td>2014</td>\n",
       "      <td>3401</td>\n",
       "      <td>13876</td>\n",
       "      <td>2378</td>\n",
       "      <td>2001</td>\n",
       "      <td>2525</td>\n",
       "      <td>4844</td>\n",
       "      <td>2000</td>\n",
       "      <td>7438</td>\n",
       "      <td>...</td>\n",
       "      <td>2378</td>\n",
       "      <td>2064</td>\n",
       "      <td>2022</td>\n",
       "      <td>2109</td>\n",
       "      <td>2000</td>\n",
       "      <td>7438</td>\n",
       "      <td>7388</td>\n",
       "      <td>4456</td>\n",
       "      <td>1012</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0     1     2      3      4     5     6     7     8     9   ...    49  \\\n",
       "0  101  2053  4255   1997   3742  6215  2179  1999  5712  2664  ...     0   \n",
       "1  101  1037  2173   1997  14038  1010  2044  4831  2198  2703  ...  2277   \n",
       "2  101  2014  3401  13876   2378  2001  2525  4844  2000  7438  ...  2378   \n",
       "\n",
       "     50    51    52    53    54    55    56    57   58  \n",
       "0     0     0     0     0     0     0     0     0    0  \n",
       "1  1012   102     0     0     0     0     0     0    0  \n",
       "2  2064  2022  2109  2000  7438  7388  4456  1012  102  \n",
       "\n",
       "[3 rows x 59 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply padding using data_collator\n",
    "batch = data_collator(samples)\n",
    "pd.DataFrame(batch[\"input_ids\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that `data_collator` will insert `[PAD]` (0) tokens to the maximum length of the passed batch of data items."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The GLUE dataset specifies one or more evaluation metrics depending on the selected task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EvaluationModule(name: \"glue\", module_type: \"metric\", features: {'predictions': Value(dtype='int64', id=None), 'references': Value(dtype='int64', id=None)}, usage: \"\"\"\n",
       "Compute GLUE evaluation metric associated to each GLUE dataset.\n",
       "Args:\n",
       "    predictions: list of predictions to score.\n",
       "        Each translation should be tokenized into a list of tokens.\n",
       "    references: list of lists of references for each translation.\n",
       "        Each reference should be tokenized into a list of tokens.\n",
       "Returns: depending on the GLUE subset, one or several of:\n",
       "    \"accuracy\": Accuracy\n",
       "    \"f1\": F1 score\n",
       "    \"pearson\": Pearson Correlation\n",
       "    \"spearmanr\": Spearman Correlation\n",
       "    \"matthews_correlation\": Matthew Correlation\n",
       "Examples:\n",
       "\n",
       "    >>> glue_metric = evaluate.load('glue', 'sst2')  # 'sst2' or any of [\"mnli\", \"mnli_mismatched\", \"mnli_matched\", \"qnli\", \"rte\", \"wnli\", \"hans\"]\n",
       "    >>> references = [0, 1]\n",
       "    >>> predictions = [0, 1]\n",
       "    >>> results = glue_metric.compute(predictions=predictions, references=references)\n",
       "    >>> print(results)\n",
       "    {'accuracy': 1.0}\n",
       "\n",
       "    >>> glue_metric = evaluate.load('glue', 'mrpc')  # 'mrpc' or 'qqp'\n",
       "    >>> references = [0, 1]\n",
       "    >>> predictions = [0, 1]\n",
       "    >>> results = glue_metric.compute(predictions=predictions, references=references)\n",
       "    >>> print(results)\n",
       "    {'accuracy': 1.0, 'f1': 1.0}\n",
       "\n",
       "    >>> glue_metric = evaluate.load('glue', 'stsb')\n",
       "    >>> references = [0., 1., 2., 3., 4., 5.]\n",
       "    >>> predictions = [0., 1., 2., 3., 4., 5.]\n",
       "    >>> results = glue_metric.compute(predictions=predictions, references=references)\n",
       "    >>> print({\"pearson\": round(results[\"pearson\"], 2), \"spearmanr\": round(results[\"spearmanr\"], 2)})\n",
       "    {'pearson': 1.0, 'spearmanr': 1.0}\n",
       "\n",
       "    >>> glue_metric = evaluate.load('glue', 'cola')\n",
       "    >>> references = [0, 1]\n",
       "    >>> predictions = [0, 1]\n",
       "    >>> results = glue_metric.compute(predictions=predictions, references=references)\n",
       "    >>> print(results)\n",
       "    {'matthews_correlation': 1.0}\n",
       "\"\"\", stored examples: 0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(DATASET_NAME, DATASET_TASK)\n",
    "metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on the selected GLUE task we optimize for different evaluation metrics. See BERT paper p.6:\n",
    "\n",
    "> F1 scores are reported for QQP and MRPC, Spearman correlations are reported for STS-B, and accuracy scores are reported for the other tasks. We exclude entries that use BERT as one of their components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "_task_to_metric = {\n",
    "    \"cola\": \"matthews_correlation\",\n",
    "    \"mnli\": \"accuracy\",\n",
    "    \"mnli-mm\": \"accuracy\",\n",
    "    \"mrpc\": \"f1\",\n",
    "    \"qnli\": \"accuracy\",\n",
    "    \"qqp\": \"f1\",\n",
    "    \"rte\": \"accuracy\",\n",
    "    \"sst2\": \"accuracy\",\n",
    "    \"stsb\": \"spearmanr\",\n",
    "}\n",
    "\n",
    "metric_for_best_model = _task_to_metric[DATASET_TASK]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We will use \"['accuracy']\" as an evaluation metric for the task rte\n"
     ]
    }
   ],
   "source": [
    "def get_metric_name_for_specific_task():\n",
    "    \"\"\"Helper function to derive the evaluation metric name for the specified GLUE task.\n",
    "\n",
    "    The tasks specified by the GLUE benchmark use different evaluation metrics.\n",
    "    Unfortunatly there is no easy way to derive there name after loading the corresponding metric function via HuggingFace's `evaluate` library.\n",
    "    However we can simply do a \"trial run\" and expect the name key of its output.\n",
    "    \"\"\"\n",
    "    output = metric.compute(\n",
    "        predictions=[1, 0], references=[1, 1]\n",
    "    )  # dummy input - we just want to inspect the returned dictionary.\n",
    "    metric_names = output.keys()\n",
    "    \n",
    "    return list(metric_names)\n",
    "\n",
    "\n",
    "metric_names = get_metric_name_for_specific_task()\n",
    "print(f'We will use \"{metric_names}\" as an evaluation metric for the task {DATASET_TASK}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert metric_for_best_model in metric_names, \"Metric to optimize for not found in evaluation metrics provided by GLUE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    PRE_TRAINED_CHECKPOINT,\n",
    "    num_labels=num_labels,\n",
    "    torch_dtype=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_arguments = TrainingArguments(\n",
    "    output_dir=TRAIN_OUTPUT_DIR,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=100,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=100,\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=100,\n",
    "    num_train_epochs=NUM_EPOCHS,\n",
    "    learning_rate=2e-5,  # Original paper uses best out of  5e-5, 4e-5, 3e-5, and 2e-5\n",
    "    weight_decay=0.01,  # Original paper uses 0.01 on pre-training\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=metric_for_best_model,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    if DATASET_TASK != \"stsb\":  # STSB is the odd one as it is a regression task\n",
    "        predictions = np.argmax(predictions, axis=1)\n",
    "    else:\n",
    "        predictions = predictions[:, 0]\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "validation_key = \"validation_mismatched\" if DATASET_TASK == \"mnli-mm\" else \"validation_matched\" if DATASET_TASK == \"mnli\" else \"validation\"\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_arguments,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[validation_key],\n",
    "    data_collator=data_collator,\n",
    "    processing_class=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- training_arguments.output_dir='../groups/192.039-2024W/bert/training/glue-rte'\n",
      "--- training_arguments.metric_for_best_model='accuracy'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c66a3aa384234f1d8604c91ab912ebf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/546 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6796, 'grad_norm': 5.41839075088501, 'learning_rate': 1.633699633699634e-05, 'epoch': 1.28}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0521577190444d8fb00b5a1a034ec2b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6506196856498718, 'eval_accuracy': 0.6173285198555957, 'eval_runtime': 1.0627, 'eval_samples_per_second': 260.656, 'eval_steps_per_second': 8.469, 'epoch': 1.28}\n",
      "{'loss': 0.5163, 'grad_norm': 6.269650459289551, 'learning_rate': 1.2673992673992674e-05, 'epoch': 2.56}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ef932f5013647998748d0df70af72ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6848298907279968, 'eval_accuracy': 0.6750902527075813, 'eval_runtime': 1.06, 'eval_samples_per_second': 261.309, 'eval_steps_per_second': 8.49, 'epoch': 2.56}\n",
      "{'loss': 0.3475, 'grad_norm': 5.83979606628418, 'learning_rate': 9.010989010989011e-06, 'epoch': 3.85}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c52f9e8e766e4bc3b8259817014e04d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7981826066970825, 'eval_accuracy': 0.6750902527075813, 'eval_runtime': 1.0723, 'eval_samples_per_second': 258.333, 'eval_steps_per_second': 8.393, 'epoch': 3.85}\n",
      "{'loss': 0.1851, 'grad_norm': 1.75528883934021, 'learning_rate': 5.347985347985348e-06, 'epoch': 5.13}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "546664a39523403d9d511307d1cee81b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.967082679271698, 'eval_accuracy': 0.6859205776173285, 'eval_runtime': 1.0741, 'eval_samples_per_second': 257.886, 'eval_steps_per_second': 8.379, 'epoch': 5.13}\n",
      "{'loss': 0.1114, 'grad_norm': 5.731241703033447, 'learning_rate': 1.6849816849816852e-06, 'epoch': 6.41}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ec82fa297db4d9fb0c8631f3291948b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0327374935150146, 'eval_accuracy': 0.6787003610108303, 'eval_runtime': 1.0722, 'eval_samples_per_second': 258.356, 'eval_steps_per_second': 8.394, 'epoch': 6.41}\n",
      "{'train_runtime': 231.0187, 'train_samples_per_second': 75.448, 'train_steps_per_second': 2.363, 'train_loss': 0.3443517772269336, 'epoch': 7.0}\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "print(f\"--- {training_arguments.output_dir=}\")\n",
    "print(f\"--- {training_arguments.metric_for_best_model=}\")\n",
    "training_summary = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=546, training_loss=0.3443517772269336, metrics={'train_runtime': 231.0187, 'train_samples_per_second': 75.448, 'train_steps_per_second': 2.363, 'total_flos': 1633825098250080.0, 'train_loss': 0.3443517772269336, 'epoch': 7.0})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can call `trainer.evaluate()` to check that the `trainer` instance did indeed reload the model checkpoint with the highest evaluation score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05baaa33b9c3458ebe6e135b481caf0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.967082679271698,\n",
       " 'eval_accuracy': 0.6859205776173285,\n",
       " 'eval_runtime': 1.0635,\n",
       " 'eval_samples_per_second': 260.45,\n",
       " 'eval_steps_per_second': 8.462,\n",
       " 'epoch': 7.0}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_evaluation = trainer.evaluate()\n",
    "best_model_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>grad_norm</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>epoch</th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>eval_accuracy</th>\n",
       "      <th>eval_runtime</th>\n",
       "      <th>eval_samples_per_second</th>\n",
       "      <th>eval_steps_per_second</th>\n",
       "      <th>train_runtime</th>\n",
       "      <th>train_samples_per_second</th>\n",
       "      <th>train_steps_per_second</th>\n",
       "      <th>total_flos</th>\n",
       "      <th>train_loss</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>step</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.6796</td>\n",
       "      <td>5.418391</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>1.282051</td>\n",
       "      <td>0.650620</td>\n",
       "      <td>0.617329</td>\n",
       "      <td>1.0627</td>\n",
       "      <td>260.656</td>\n",
       "      <td>8.469</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>0.5163</td>\n",
       "      <td>6.269650</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>2.564103</td>\n",
       "      <td>0.684830</td>\n",
       "      <td>0.675090</td>\n",
       "      <td>1.0600</td>\n",
       "      <td>261.309</td>\n",
       "      <td>8.490</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>0.3475</td>\n",
       "      <td>5.839796</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>3.846154</td>\n",
       "      <td>0.798183</td>\n",
       "      <td>0.675090</td>\n",
       "      <td>1.0723</td>\n",
       "      <td>258.333</td>\n",
       "      <td>8.393</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>0.1851</td>\n",
       "      <td>1.755289</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>5.128205</td>\n",
       "      <td>0.967083</td>\n",
       "      <td>0.685921</td>\n",
       "      <td>1.0741</td>\n",
       "      <td>257.886</td>\n",
       "      <td>8.379</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>0.1114</td>\n",
       "      <td>5.731242</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>6.410256</td>\n",
       "      <td>1.032737</td>\n",
       "      <td>0.678700</td>\n",
       "      <td>1.0722</td>\n",
       "      <td>258.356</td>\n",
       "      <td>8.394</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.967083</td>\n",
       "      <td>0.685921</td>\n",
       "      <td>1.0635</td>\n",
       "      <td>260.450</td>\n",
       "      <td>8.462</td>\n",
       "      <td>231.0187</td>\n",
       "      <td>75.448</td>\n",
       "      <td>2.363</td>\n",
       "      <td>1.633825e+15</td>\n",
       "      <td>0.344352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        loss  grad_norm  learning_rate     epoch  eval_loss  eval_accuracy  \\\n",
       "step                                                                         \n",
       "100   0.6796   5.418391       0.000016  1.282051   0.650620       0.617329   \n",
       "200   0.5163   6.269650       0.000013  2.564103   0.684830       0.675090   \n",
       "300   0.3475   5.839796       0.000009  3.846154   0.798183       0.675090   \n",
       "400   0.1851   1.755289       0.000005  5.128205   0.967083       0.685921   \n",
       "500   0.1114   5.731242       0.000002  6.410256   1.032737       0.678700   \n",
       "546      NaN        NaN            NaN  7.000000   0.967083       0.685921   \n",
       "\n",
       "      eval_runtime  eval_samples_per_second  eval_steps_per_second  \\\n",
       "step                                                                 \n",
       "100         1.0627                  260.656                  8.469   \n",
       "200         1.0600                  261.309                  8.490   \n",
       "300         1.0723                  258.333                  8.393   \n",
       "400         1.0741                  257.886                  8.379   \n",
       "500         1.0722                  258.356                  8.394   \n",
       "546         1.0635                  260.450                  8.462   \n",
       "\n",
       "      train_runtime  train_samples_per_second  train_steps_per_second  \\\n",
       "step                                                                    \n",
       "100             NaN                       NaN                     NaN   \n",
       "200             NaN                       NaN                     NaN   \n",
       "300             NaN                       NaN                     NaN   \n",
       "400             NaN                       NaN                     NaN   \n",
       "500             NaN                       NaN                     NaN   \n",
       "546        231.0187                    75.448                   2.363   \n",
       "\n",
       "        total_flos  train_loss  \n",
       "step                            \n",
       "100            NaN         NaN  \n",
       "200            NaN         NaN  \n",
       "300            NaN         NaN  \n",
       "400            NaN         NaN  \n",
       "500            NaN         NaN  \n",
       "546   1.633825e+15    0.344352  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_history = pd.DataFrame(trainer.state.log_history)\n",
    "training_history.groupby(\"step\").first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Loss and Evaluation Metrics over Training Steps"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "data = training_history[[\"loss\", \"eval_loss\", \"step\", f\"eval_{metric_for_best_model}\"]]\n",
    "data.columns = [\"Train. Loss\", \"Eval. Loss\", \"Training Steps\", \"Acc.\"]\n",
    "data = pd.melt(data, ['Training Steps'])\n",
    "\n",
    "plot = sns.lineplot(data=data, x=\"Training Steps\", y=\"value\", hue=\"variable\", style=\"variable\", markers=True)\n",
    "plot.set_ylabel(\"\")\n",
    "plot.set_ylim((0, plot.get_ylim()[1]))\n",
    "plot.legend(title=\"\")\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "display(Markdown(\"### Loss and Evaluation Metrics over Training Steps\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** For some reason this plot seems awry. The accuracy metric is hardly improving, while evaluation loss increases over training. It seems that fine-tuning on this tasks always results in overfitting.  \n",
    "One reason might be that this GLUE task has by far the smallest dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Best Model performance:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Our Model\" based on google-bert/bert-base-uncased, best performance on validation data.\n",
      "\"BERT_BASE\" and \"BERT_LARGE\" performance on GLUE testing data as reported in original paper.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Our Model</th>\n",
       "      <th>original BERT_BASE</th>\n",
       "      <th>original BERT_LARGE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>eval_loss</th>\n",
       "      <td>0.967083</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_accuracy</th>\n",
       "      <td>0.685921</td>\n",
       "      <td>0.664</td>\n",
       "      <td>0.701</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Our Model original BERT_BASE original BERT_LARGE\n",
       "eval_loss       0.967083                  -                   -\n",
       "eval_accuracy   0.685921              0.664               0.701"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(Markdown(f\"### Best Model performance:\"))\n",
    "results = pd.DataFrame(\n",
    "    best_model_evaluation.values(),\n",
    "    index=best_model_evaluation.keys(),\n",
    "    columns=[\"Our Model\"],\n",
    ").drop(\n",
    "    # Drop runtime measurements\n",
    "    index=[\"eval_runtime\", \"eval_samples_per_second\", \"eval_steps_per_second\", \"epoch\"]\n",
    ")\n",
    "# Achieved scores from original BERT paper:\n",
    "results[\"original BERT_BASE\"] = [\"-\", 0.664]\n",
    "results[\"original BERT_LARGE\"] = [\"-\", 0.701]\n",
    "print(f'\"Our Model\" based on {PRE_TRAINED_CHECKPOINT}, best performance on validation data.')\n",
    "print('\"BERT_BASE\" and \"BERT_LARGE\" performance on GLUE testing data as reported in original paper.')\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
